\section{Projekt systemu przetwarzania danych w czasie rzeczywistym}
\label{sec:projekt_systemu}

W niniejszym rozdziale przedstawiono projekt systemu do analizy danych w czasie rzeczywistym z systemów wieloczujnikowych, opartego na klastrze Kubernetes oraz narzędziach Big Data. Omówiono wymagania systemu, architekturę, model danych oraz przepływ danych.

\subsection{Wymagania systemu}
\label{subsec:wymagania}

Na podstawie analizy literatury oraz istniejących rozwiązań, zidentyfikowano następujące wymagania dla projektowanego systemu:

\subsubsection{Wymagania funkcjonalne}
\label{subsubsec:wymagania_funkcjonalne}

\begin{enumerate}
    \item \textbf{Pozyskiwanie danych} - system powinien umożliwiać pozyskiwanie danych z różnych typów czujników
   \item , w tym:
   \begin{itemize}
       \item Czujników temperatury
       \item Czujników ciśnienia
       \item Czujników przepływu
       \item Czujników drgań
   \end{itemize}
    
    \item \textbf{Przetwarzanie danych} - system powinien umożliwiać przetwarzanie danych w czasie rzeczywistym, w tym:
    \begin{itemize}
        \item Filtrację danych
        \item Agregację danych w różnych oknach czasowych
        \item Klasyfikację awarii
        \item Generowanie zdarzeń
    \end{itemize}
    
    \item \textbf{Wizualizacja danych} - system powinien umożliwiać wizualizację danych w czasie rzeczywistym, w tym:
    \begin{itemize}
        \item Wykresy liniowe
        \item Wskaźniki i mierniki
        \item Alerty i powiadomienia
    \end{itemize}
    
   \item \textbf{Zarządzanie użytkownikami} - system powinien umożliwiać zarządzanie użytkownikami, w tym:
   \begin{itemize}
       \item Logowanie użytkowników
       \item Różne poziomy uprawnień (admin, operator, gość)
       \item Rejestrację użytkowników z poziomu panelu administracyjnego
       \item Kontrolę dostępu do danych
   \end{itemize}
    
    \item \textbf{Raportowanie} - system powinien umożliwiać generowanie raportów, w tym:
   \begin{itemize}
       \item Tworzenie raportów dla dowolnej zakresu czasu
       \item Edycję raportów
       \item Wyszukiwanie raportów na podstawie różnych kryteriów
   \end{itemize}
\end{enumerate}

\subsubsection{Wymagania niefunkcjonalne}
\label{subsubsec:wymagania_niefunkcjonalne}

\begin{enumerate}
    
    \item \textbf{Skalowalność} - system powinien umożliwiać:
    \begin{itemize}
        \item Skalowanie horyzontalne (dodawanie nowych węzłów)
        \item Automatyczne skalowanie w zależności od obciążenia
    \end{itemize}
    
    \item \textbf{Niezawodność} - system powinien charakteryzować się:
    \begin{itemize}
        \item Odpornością na awarie pojedynczych komponentów
    \end{itemize}
    
    \item \textbf{Bezpieczeństwo} - system powinien zapewniać:
    \begin{itemize}
        \item Szyfrowanie danych w spoczynku i w transporcie
        \item Uwierzytelnianie i autoryzację użytkowników
        \item Audytowanie dostępu do danych
    \end{itemize}
    
    \item \textbf{Utrzymywalność} - system powinien charakteryzować się:
    \begin{itemize}
        \item Modułową architekturą
        \item Dobrą dokumentacją
        \item Łatwością rozszerzania i modyfikacji
    \end{itemize}
\end{enumerate}

\subsection{Architektura systemu}
\label{subsec:architektura}

Projektowany system opiera się na architekturze mikroserwisowej, wdrożonej na klastrze Kubernetes.
Architektura składa się z kilku kluczowych warstw, przedstawionych na Rysunku \ref{Architektura systemu do analizy danych w czasie rzeczywistym}.

\singlesizedimageforced{images/architektura.png}{Architektura systemu do analizy danych w czasie rzeczywistym}{0.8}

\subsubsection{Warstwa pozyskiwania danych (symulatory czujników)}
\label{subsubsec:warstwa_pozyskiwania}

Warstwa pozyskiwania danych odpowiada za zbieranie danych z czujników i ich wstępne przetworzenie.
W projektowanym systemie, dane są generowane przez symulatory czujników implementowane jako funkcje AWS Lambda.
Symulatory te generują dane symulujące odczyty z różnych typów czujników.

Dane generowane przez symulatory są formatowane jako wiadomości JSON i publikowane na tematy SNS, a następnie przenoszone do kolejek SQS,
które stanowią interfejs między AWS a klastrem Kubernetes.

\subsubsection{Warstwa komunikacji (Apache Kafka)}
\label{subsubsec:warstwa_komunikacji}

Warstwa komunikacji odpowiada za odbieranie danych z warstwy pozyskiwania i ich dostarczanie do warstwy przetwarzania.
W projektowanym systemie, warstwa ta opiera się na Apache Kafka, rozproszonej platformie do przetwarzania strumieniowego.


Apache Kafka zapewnia trwałość danych, wysoką przepustowość i skalowalność, co jest kluczowe w kontekście przetwarzania danych w czasie rzeczywistym z wielu czujników.

\subsubsection{Warstwa przetwarzania (Apache Spark)}
\label{subsubsec:warstwa_przetwarzania}

Warstwa przetwarzania odpowiada za analizę danych w czasie rzeczywistym. W projektowanym systemie, warstwa ta opiera się na frameworku Apache Spark, wykorzystując jego moduł Spark Structured Streaming do przetwarzania strumieni danych. Głównym komponentem tej warstwy jest aplikacja \texttt{SparkDataProcessor}, zrealizowana w języku Scala. Aplikacja ta zawiera logikę przetwarzania danych, podzieloną na wyspecjalizowane moduły takie jak \texttt{MeanProcessor} (obliczanie średnich), \texttt{EventProcessor} (wykrywanie zdarzeń na podstawie progów) oraz \texttt{EquipmentStateProcessor} (predykcja stanu urządzenia przy użyciu modelu uczenia maszynowego RandomForestClassifier). Szczegółowy opis tych modułów oraz ich działania znajduje się w Rozdziale \ref{sec:algorytmy_analizy}.

Apache Spark umożliwia przetwarzanie danych strumieniowych z wykorzystaniem zaawansowanych operacji, obsługę danych opóźnionych (watermarks), zarządzanie stanem oraz integrację z bibliotekami uczenia maszynowego (Spark ML), co jest kluczowe w kontekście kompleksowej analizy danych z systemów wieloczujnikowych.

\subsubsection{Warstwa składowania danych}
\label{subsubsec:warstwa_skladowania}

Warstwa składowania danych odpowiada za przechowywanie przetworzonych danych do dalszej analizy i wizualizacji. W projektowanym systemie, warstwa ta składa się z dwóch głównych komponentów:

\begin{itemize}
    \item \textbf{PostgreSQL} - relacyjna baza danych, przechowująca ustrukturyzowane dane, takie jak odczyty czujników, metadane czy informacje o użytkownikach
    \item \textbf{Elasticsearch} - baza danych NoSQL, umożliwiająca szybkie wyszukiwanie i analizę danych, szczególnie przydatna w kontekście wykrywania anomalii i analizy trendów
\end{itemize}

\subsubsection{Warstwa usług i API}
\label{subsubsec:warstwa_uslug}

Warstwa usług i API odpowiada za udostępnianie danych i funkcjonalności systemu zewnętrznym aplikacjom i użytkownikom. W projektowanym systemie,
warstwa ta składa się z kilku mikroserwisów:

\begin{itemize}
    \item \textbf{Data Service} - mikroserwis udostępniający API do dostępu do danych z czujników, umożliwiający tworzenie i pobieranie raportów
    \item \textbf{Users Service} - mikroserwis zarządzający użytkownikami i uwierzytelnianiem, wykorzystujący Keycloak jako system zarządzania tożsamością
    \item \textbf{Front Service} - mikroserwis pełniący rolę API Gateway, który ekspozuje API innych mikroserwisów na zewnątrz klastra
\end{itemize}

Wszystkie mikroserwisy są implementowane jako aplikacje Spring Boot, co zapewnia łatwość rozwoju, testowania i wdrażania.

\subsubsection{Warstwa prezentacji}
\label{subsubsec:warstwa_prezentacji}

Warstwa prezentacji odpowiada za wizualizację danych i interakcję z użytkownikami.
W projektowanym systemie, warstwa ta składa się z dashboardu, który wyświetla dane w formie wykresów, tabel i widżetów.

Główne funkcjonalności dashboardu to:

\begin{itemize}
    \item \textbf{Wykresy liniowe} - wizualizacja zmian parametrów w czasie
    \item \textbf{Wskaźniki i mierniki} - wizualizacja aktualnych wartości parametrów
    \item \textbf{Alerty} - powiadomienia o anomaliach i potencjalnych awariach
    \item \textbf{Raporty} - generowanie i przeglądanie raportów
\end{itemize}

Dashboard jest implementowany jako aplikacja webowa, wykorzystująca React i biblioteki wizualizacji danych.

\subsection{Model danych}
\label{subsec:model_danych}

Model danych projektowanego systemu składa się z kilku kluczowych encji, przedstawionych na Rysunku \ref{Model danych systemu}.

\singlesizedimageforced{images/datamodel.png}{Model danych systemu}{0.8}

\subsubsection{Dane z czujników}
\label{subsubsec:dane_czujnikow}

Dane z czujników są modelowane jako strumienie zdarzeń, gdzie każde zdarzenie zawiera:

\begin{itemize}
    \item \textbf{Typ czujnika} - rodzaj czujnika (temperatura, ciśnienie, przepływ, skład gazu, drgania)
    \item \textbf{Znacznik lokalizacji} - miejsce, w którym znajduje się czujnik
    \item \textbf{Znacznik czasu} - czas, w którym dokonano pomiaru
    \item \textbf{Wartość} - wartość pomiaru
    \item \textbf{Jednostka} - jednostka, w której wyrażona jest wartość
\end{itemize}

Dane te są serializowane przy użyciu Apache Avro, co zapewnia efektywne kodowanie i dekodowanie wiadomości.

\subsubsection{Przetworzone dane}
\label{subsubsec:przetworzone_dane}

Przetworzone dane są wynikiem analizy danych surowych przez aplikację \texttt{SparkDataProcessor} i obejmują:

\begin{itemize}
    \item \textbf{Agregacje (Aggregations)} - średnie wartości oraz liczba odczytów dla poszczególnych typów sensorów, obliczane przez moduł \texttt{MeanProcessor} w zdefiniowanych oknach czasowych:
    \begin{itemize}
        \item \textit{sensor_type} - typ sensora (np. "pressure", "temperature")
        \item \textit{label} - etykieta urządzenia (np. "pump", "compressor")
        \item \textit{window_start} - początek okna czasowego
        \item \textit{window_end} - koniec okna czasowego
        \item \textit{avg_value} - średnia wartość pomiarów w oknie
        \item \textit{count} - liczba pomiarów w oknie
    \end{itemize}
    
    \item \textbf{Zdarzenia (Events)} - wykryte przez moduł \texttt{EventProcessor} przekroczenia zdefiniowanych progów ostrzegawczych i krytycznych dla danych sensorycznych:
    \begin{itemize}
        \item \textit{event_id} - unikalny identyfikator zdarzenia
        \item \textit{sensor_type} - typ sensora, którego dotyczy zdarzenie
        \item \textit{label} - etykieta urządzenia
        \item \textit{timestamp} - czas wykrycia zdarzenia
        \item \textit{title} - tytuł zdarzenia (np. "Przekroczenie progu krytycznego dla ciśnienia")
        \item \textit{status} - status alertu (np. "Ostrzeżenie", "Krytyczny")
        \item \textit{actual_value} - rzeczywista wartość, która spowodowała zdarzenie
    \end{itemize}
    
    \item \textbf{Dane wzbogacone o predykcję stanu (Augmented Data with Predicted Status)} - oryginalne dane sensoryczne wzbogacone o sklasyfikowany stan urządzenia, generowane przez moduł \texttt{EquipmentStateProcessor} z użyciem modelu \texttt{RandomForestClassifier}:
    \begin{itemize}
        \item \textit{original_sensor_data} - pełny zestaw oryginalnych danych z sensora (np. ciśnienie, temperatura wraz ze znacznikiem czasu, typem urządzenia itp.)
        \item \textit{predicted_status} - przewidziany stan urządzenia (np. "Stan normalny", "Wczesne zużycie", "Stan podkrytyczny", "Stan krytyczny", "Naprawa")
        \item \textit{model_type} - typ modelu użytego do predykcji (tutaj: \texttt{RandomForestClassifier})
    \end{itemize}
\end{itemize}

Wszystkie te dane są serializowane do formatu Avro i publikowane na dedykowane tematy Kafka. Następnie, wybrane dane (np. zdarzenia, zagregowane dane do wizualizacji) mogą być zapisywane w bazach danych takich jak PostgreSQL lub Elasticsearch przez dedykowane serwisy (np. \texttt{Kafka-DB-Forwarder}).

\subsection{Przepływ danych w systemie}
\label{subsec:przeplyw_danych}

Przepływ danych w projektowanym systemie obejmuje kilka etapów, przedstawionych na Rysunku \ref{Przepływ danych w systemie}.

\singlesizedimageforced{images/data_flow.png}{Przepływ danych w systemie}{0.8}

\subsubsection{Generowanie danych}
\label{subsubsec:generowanie_danych}

Proces rozpoczyna się od generowania danych przez symulatory czujników. Symulatory te są implementowane jako funkcje AWS Lambda,
które są wyzwalane periodycznie przez AWS Step Functions. Każdy symulator generuje dane symulujące odczyty z określonego typu czujnika,
umieszczonego w określonym miejscu instalacji do syntezy amoniaku.

Dane są generowane w formacie JSON i zawierają informacje takie jak identyfikator czujnika, typ, lokalizacja, znacznik czasu, wartość i
jednostka. Dane te są następnie publikowane na temat SNS (Simple Notification Service), który działa jako punkt dystrybucji dla wielu subskrybentów.

\subsubsection{Przesyłanie danych do klastra}
\label{subsubsec:przesylanie_danych}

Dane opublikowane na temacie SNS są automatycznie dostarczane do kolejek SQS (Simple Queue Service), które są subskrybentami tematu. Kolejki SQS działają jako bufor między AWS a klastrem Kubernetes, zapewniając niezawodne dostarczanie wiadomości, nawet w przypadku tymczasowej niedostępności klastra.

W klastrze Kubernetes działa mikroserwis SQS-Kafka-Forwarder, który regularnie odpytuje kolejki SQS i pobiera nowe wiadomości. Wiadomości te są następnie deserializowane i publikowane na odpowiednie tematy Kafka, w zależności od typu czujnika i lokalizacji.

\subsubsection{Przetwarzanie strumieni danych}
\label{subsubsec:przetwarzanie_strumieni}

Dane opublikowane na tematach Kafka są przetwarzane przez mikroserwis \texttt{SparkDataProcessor}, który wykorzystuje Apache Spark (Spark Structured Streaming) do analizy danych w czasie rzeczywistym. Przetwarzanie obejmuje:

\begin{itemize}
    \item \textbf{Obliczanie średnich wartości} dla poszczególnych typów sensorów w zdefiniowanych oknach czasowych (moduł \texttt{MeanProcessor}).
    \item \textbf{Wykrywanie zdarzeń} na podstawie przekroczenia zdefiniowanych progów ostrzegawczych i krytycznych (moduł \texttt{EventProcessor}).
    \item \textbf{Predykcję ogólnego stanu technicznego} monitorowanego urządzenia na podstawie połączonych danych z wielu sensorów, przy użyciu modelu \texttt{RandomForestClassifier} (moduł \texttt{EquipmentStateProcessor}).
    \item \textbf{Wzbogacanie oryginalnych danych} sensorycznych o przewidzianą etykietę stanu.
\end{itemize}

Wyniki przetwarzania, w formacie Avro, są publikowane na nowe, dedykowane tematy Kafka.

\subsubsection{Zapisywanie danych do bazy danych}
\label{subsubsec:zapisywanie_danych}

Przetworzone dane są konsumowane przez mikroserwis Kafka-DB-Forwarder, który zapisuje je do baz danych. Dane strukturalne, takie jak odczyty czujników,
agregacje i metadane, są zapisywane do bazy danych PostgreSQL.

Zapisywanie danych do baz danych umożliwia ich późniejszą analizę, raportowanie i wizualizację, a także zapewnia trwałość danych.

\subsubsection{Udostępnianie danych przez API}
\label{subsubsec:udostepnianie_danych}

Zapisane dane są udostępniane przez mikroserwis Data-Service, który ekspozuje REST API do tworzenia i pobierania raportów. API to umożliwia:

\begin{itemize}
    \item \textbf{Pobieranie danych surowych} - dostęp do nieprzetworzonych odczytów czujników
    \item \textbf{Pobieranie danych przetworzonych} - dostęp do agregacji, wykrytych anomalii, predykcji
    \item \textbf{Tworzenie raportów} - generowanie raportów na podstawie zadanych kryteriów
    \item \textbf{Pobieranie raportów} - dostęp do wcześniej wygenerowanych raportów
\end{itemize}

API jest zabezpieczone mechanizmami uwierzytelniania i autoryzacji, implementowanymi przez mikroserwis Users-Service, który korzysta z Keycloak.

\subsubsection{Wizualizacja danych}
\label{subsubsec:wizualizacja_danych}

Ostatnim etapem przepływu danych jest ich wizualizacja na dashboardzie. Dashboard komunikuje się z API, pobierając dane do wyświetlenia, a następnie prezentuje je w formie wykresów, tabel i widżetów.

Dashboard umożliwia interaktywną eksplorację danych, filtrowanie, sortowanie i eksport wyników. Ponadto, dashboard może wyświetlać alerty i powiadomienia o wykrytych anomaliach i potencjalnych awariach.

Przepływ danych w projektowanym systemie zapewnia efektywne pozyskiwanie, przetwarzanie i analizę danych w czasie rzeczywistym, co jest kluczowe w kontekście monitorowania i optymalizacji procesu syntezy amoniaku. 