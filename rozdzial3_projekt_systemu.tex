\section{Projekt systemu przetwarzania danych w czasie rzeczywistym}
\label{sec:projekt_systemu}

W niniejszym rozdziale przedstawiono projekt systemu do analizy danych w czasie rzeczywistym z systemów wieloczujnikowych, opartego na klastrze Kubernetes oraz narzędziach Big Data. Omówiono wymagania systemu, architekturę, model danych oraz przepływ danych.

\subsection{Wymagania systemu}
\label{subsec:wymagania}

Na podstawie analizy literatury \ref{sec:przeglad_literatury} oraz istniejących rozwiązań, zidentyfikowano przedstawione poniżej wymagania dla projektowanego systemu.

\subsubsection{Wymagania funkcjonalne}
\label{subsubsec:wymagania_funkcjonalne}

\begin{itemize}
    \item \textbf{pozyskiwanie danych} - system powinien umożliwiać pozyskiwanie danych z różnych typów czujników, w tym:
   \begin{itemize}
       \item czujników temperatury,
       \item czujników ciśnienia,
       \item czujników przepływu,
       \item czujników drgań.
   \end{itemize}
    
    \item \textbf{przetwarzanie danych} - system powinien umożliwiać przetwarzanie danych w czasie rzeczywistym, w tym:
    \begin{itemize}
        \item filtrację danych,
        \item agregację danych w różnych oknach czasowych,
        \item klasyfikację awarii,
        \item generowanie zdarzeń.
    \end{itemize}
    
    \item \textbf{wizualizacja danych} - system powinien umożliwiać wizualizację danych w czasie rzeczywistym, w tym:
    \begin{itemize}
        \item wykresy liniowe,
        \item wskaźniki i mierniki,
        \item alerty i powiadomienia.
    \end{itemize}
    
   \item \textbf{zarządzanie użytkownikami} - system powinien umożliwiać zarządzanie użytkownikami, w tym:
   \begin{itemize}
       \item logowanie użytkowników,
       \item różne poziomy uprawnień (admin, operator, gość),
       \item rejestrację użytkowników z poziomu panelu administracyjnego,
       \item kontrolę dostępu do danych.
   \end{itemize}
    
    \item \textbf{raportowanie} - system powinien umożliwiać generowanie raportów, w tym:
   \begin{itemize}
       \item tworzenie raportów dla dowolnej zakresu czasu,
       \item edycję raportów,
       \item wyszukiwanie raportów na podstawie różnych kryteriów.
   \end{itemize}
\end{itemize}

\subsubsection{Wymagania niefunkcjonalne}
\label{subsubsec:wymagania_niefunkcjonalne}

\begin{itemize}
    
    \item \textbf{skalowalność} - system powinien umożliwiać:
    \begin{itemize}
        \item skalowanie horyzontalne (dodawanie nowych węzłów),
        \item automatyczne skalowanie w zależności od obciążenia.
    \end{itemize}
    
    \item \textbf{niezawodność} - system powinien charakteryzować się:
    \begin{itemize}
        \item odpornością na awarie pojedynczych komponentów.
    \end{itemize}
    
    \item \textbf{bezpieczeństwo} - system powinien zapewniać:
    \begin{itemize}
        \item szyfrowanie danych w spoczynku i w transporcie,
        \item uwierzytelnianie i autoryzację użytkowników,
        \item audytowanie dostępu do danych.
    \end{itemize}
    
    \item \textbf{utrzymywalność} - system powinien charakteryzować się:
    \begin{itemize}
        \item modułową architekturą,
        \item dobrą dokumentacją,
        \item łatwością rozszerzania i modyfikacji.
    \end{itemize}
\end{itemize}

\subsection{Architektura systemu}
\label{subsec:architektura}

Projektowany system opiera się na architekturze mikroserwisowej, wdrożonej na klastrze Kubernetes \cite{kubernetes_benefits}.
Architektura składa się z kilku kluczowych warstw, przedstawionych na rysunku \ref{Architektura systemu do analizy danych w czasie rzeczywistym}.

\singlesizedimageforced{images/architektura.png}{Architektura systemu do analizy danych w czasie rzeczywistym}{1.0}

\subsubsection{Warstwa pozyskiwania danych (symulatory czujników)}
\label{subsubsec:warstwa_pozyskiwania}

Warstwa pozyskiwania danych odpowiada za zbieranie danych z czujników i ich wstępne przetworzenie.
W projektowanym systemie, dane są generowane przez symulatory czujników implementowane jako funkcje AWS Lambda \cite{aws_lambda_docs}.
Symulatory te generują dane symulujące odczyty z różnych typów czujników.

Dane generowane przez symulatory są formatowane jako wiadomości JSON \cite{json_documentation} i publikowane na tematy SNS \cite{sns_docs}, a następnie przenoszone do kolejek SQS (Amazon Simple Queue Service, zarządzana usługa kolejkowania wiadomości),
które stanowią interfejs między AWS a klastrem Kubernetes.

\subsubsection{Warstwa komunikacji (Apache Kafka)}
\label{subsubsec:warstwa_komunikacji}

Warstwa komunikacji odpowiada za odbieranie danych z warstwy pozyskiwania i ich dostarczanie do warstwy przetwarzania.
W projektowanym systemie, warstwa ta opiera się na Apache Kafka \cite{kafka}, rozproszonej platformie do przetwarzania strumieniowego.


Apache Kafka zapewnia trwałość danych, wysoką przepustowość i skalowalność, co jest kluczowe w kontekście przetwarzania danych w czasie rzeczywistym z wielu czujników.

\subsubsection{Warstwa przetwarzania (Apache Spark)}
\label{subsubsec:warstwa_przetwarzania}

Warstwa przetwarzania odpowiada za analizę danych w czasie rzeczywistym. W projektowanym systemie, warstwa ta opiera się na frameworku Apache Spark \cite{spark_streaming}, wykorzystując jego moduł Spark Structured Streaming do przetwarzania strumieni danych. Głównym komponentem tej warstwy jest aplikacja \texttt{SparkDataProcessor}, zrealizowana w języku Scala. Aplikacja ta zawiera logikę przetwarzania danych, podzieloną na wyspecjalizowane moduły takie jak: \texttt{MeanProcessor} (obliczanie średnich), \texttt{EventProcessor} (wykrywanie zdarzeń na podstawie progów) oraz \texttt{EquipmentStateProcessor} (predykcja stanu urządzenia przy użyciu modelu uczenia maszynowego RandomForestClassifier). Szczegółowy opis tych modułów oraz ich działania znajduje się w Rozdziale \ref{sec:algorytmy_analizy}.

Apache Spark umożliwia przetwarzanie danych strumieniowych z wykorzystaniem zaawansowanych operacji, obsługę danych opóźnionych (watermarks), zarządzanie stanem oraz integrację z bibliotekami uczenia maszynowego (Spark ML), co jest kluczowe w kontekście kompleksowej analizy danych z systemów wieloczujnikowych.

\subsubsection{Warstwa składowania danych}
\label{subsubsec:warstwa_skladowania}

Warstwa składowania danych odpowiada za przechowywanie przetworzonych danych do dalszej analizy i wizualizacji. W projektowanym systemie, warstwa ta składa się z dwóch głównych komponentów:

\begin{itemize}
    \item \textbf{PostgreSQL} - relacyjna baza danych, przechowująca ustrukturyzowane dane, takie jak: odczyty czujników, metadane czy informacje o użytkownikach,
    \item \textbf{Elasticsearch} - baza danych NoSQL \cite{nosql_definition}, umożliwiająca szybkie wyszukiwanie i analizę danych, szczególnie przydatna w kontekście wykrywania anomalii i analizy trendów.
\end{itemize}

\subsubsection{Warstwa usług i API}
\label{subsubsec:warstwa_uslug}

Warstwa usług i API odpowiada za udostępnianie danych i funkcjonalności systemu zewnętrznym aplikacjom i użytkownikom. W projektowanym systemie,
warstwa ta składa się z kilku mikroserwisów:

\begin{itemize}
    \item \textbf{Data Service} - mikroserwis udostępniający API do dostępu do danych z czujników, umożliwiający tworzenie i pobieranie raportów,
    \item \textbf{Users Service} - mikroserwis zarządzający użytkownikami i uwierzytelnianiem, wykorzystujący Keycloak jako system zarządzania tożsamością,
    \item \textbf{Front Service} - mikroserwis pełniący rolę API Gateway \cite{api_gateway_definition}, który ekspozuje API innych mikroserwisów na zewnątrz klastra.
\end{itemize}

Wszystkie mikroserwisy są implementowane jako aplikacje Spring Boot, co zapewnia łatwość rozwoju, testowania i wdrażania.

\subsubsection{Warstwa prezentacji}
\label{subsubsec:warstwa_prezentacji}

Warstwa prezentacji odpowiada za wizualizację danych i interakcję z użytkownikami.
W projektowanym systemie, warstwa ta składa się z dashboardu, który wyświetla dane w formie wykresów, tabel i widżetów.

Główne funkcjonalności dashboardu to:

\begin{itemize}
    \item \textbf{wykresy liniowe} - wizualizacja zmian parametrów w czasie,
    \item \textbf{wskaźniki i mierniki} - wizualizacja aktualnych wartości parametrów,
    \item \textbf{alerty} - powiadomienia o anomaliach i potencjalnych awariach,
    \item \textbf{raporty} - generowanie i przeglądanie raportów.
\end{itemize}

Dashboard jest implementowany jako aplikacja webowa, wykorzystująca React i biblioteki wizualizacji danych.

\subsection{Model danych}
\label{subsec:model_danych}

Model danych projektowanego systemu składa się z kilku kluczowych encji, przedstawionych na rysunku \ref{Model danych systemu}.

\singlesizedimageforced{images/datamodel.png}{Model danych systemu}{0.8}

\subsubsection{Dane z czujników}
\label{subsubsec:dane_czujnikow}

Dane z czujników są modelowane jako strumienie zdarzeń, gdzie każde zdarzenie zawiera:

\begin{itemize}
    \item \textbf{typ czujnika} - rodzaj czujnika (temperatura, ciśnienie, przepływ, skład gazu, drgania),
    \item \textbf{znacznik lokalizacji} - miejsce, w którym znajduje się czujnik,
    \item \textbf{znacznik czasu} - czas, w którym dokonano pomiaru,
    \item \textbf{wartość} - wartość pomiaru,
    \item \textbf{jednostka} - jednostka, w której wyrażona jest wartość.
\end{itemize}

Dane te są serializowane przy użyciu Apache Avro \cite{avro_documentation}, co zapewnia efektywne kodowanie i dekodowanie wiadomości.

\subsubsection{Przetworzone dane}
\label{subsubsec:przetworzone_dane}

Przetworzone dane są wynikiem analizy danych surowych przez aplikację \texttt{SparkDataProcessor} i obejmują:

\begin{itemize}
    \item \textbf{agregacje (Aggregations)} - średnie wartości oraz liczba odczytów dla poszczególnych typów sensorów, obliczane przez moduł \texttt{MeanProcessor} w zdefiniowanych oknach czasowych:
    \begin{itemize}
        \item \textit{sensor_type} - typ sensora (np. "pressure", "temperature"),
        \item \textit{label} - etykieta urządzenia (np. "pump", "compressor"),
        \item \textit{window_start} - początek okna czasowego,
        \item \textit{window_end} - koniec okna czasowego,
        \item \textit{avg_value} - średnia wartość pomiarów w oknie,
        \item \textit{count} - liczba pomiarów w oknie.
    \end{itemize}
    
    \item \textbf{zdarzenia (Events)} - wykryte przez moduł \texttt{EventProcessor} przekroczenia zdefiniowanych progów ostrzegawczych i krytycznych dla danych sensorycznych:
    \begin{itemize}
        \item \textit{event_id} - unikalny identyfikator zdarzenia,
        \item \textit{sensor_type} - typ sensora, którego dotyczy zdarzenie,
        \item \textit{label} - etykieta urządzenia,
        \item \textit{timestamp} - czas wykrycia zdarzenia,
        \item \textit{title} - tytuł zdarzenia (np. "Przekroczenie progu krytycznego dla ciśnienia"),
        \item \textit{status} - status alertu (np. "Ostrzeżenie", "Krytyczny"),
        \item \textit{actual_value} - rzeczywista wartość, która spowodowała zdarzenie.
    \end{itemize}
    
    \item \textbf{dane wzbogacone o predykcję stanu (Augmented Data with Predicted Status)} - oryginalne dane sensoryczne wzbogacone o sklasyfikowany stan urządzenia, generowane przez moduł \texttt{EquipmentStateProcessor} z użyciem modelu \texttt{RandomForestClassifier}:
    \begin{itemize}
        \item \textit{original_sensor_data} - pełny zestaw oryginalnych danych z sensora (np. ciśnienie, temperatura wraz ze znacznikiem czasu, typem urządzenia itp.),
        \item \textit{predicted_status} - przewidziany stan urządzenia (np. "Stan normalny", "Wczesne zużycie", "Stan podkrytyczny", "Stan krytyczny", "Naprawa"),
        \item \textit{model_type} - typ modelu użytego do predykcji (tutaj: \texttt{RandomForestClassifier}).
    \end{itemize}
\end{itemize}

Wszystkie te dane są serializowane do formatu Avro i publikowane na dedykowane tematy Kafka. Następnie, wybrane dane (np. zdarzenia, zagregowane dane do wizualizacji) mogą być zapisywane w bazach danych takich jak PostgreSQL lub Elasticsearch przez dedykowane serwisy (np. \texttt{Kafka-DB-Forwarder}).

\subsection{Przepływ danych w systemie}
\label{subsec:przeplyw_danych}

Przepływ danych w projektowanym systemie obejmuje kilka etapów, przedstawionych na rysunku \ref{Przepływ danych w systemie}.

\singlesizedimageforced{images/data_flow.png}{Przepływ danych w systemie}{0.8}

\subsubsection{Generowanie danych}
\label{subsubsec:generowanie_danych}

Proces rozpoczyna się od generowania danych przez symulatory czujników. Symulatory te są implementowane jako funkcje AWS Lambda \cite{aws_lambda_docs},
które są wyzwalane periodycznie przez AWS Step Functions \cite{aws_step_functions_docs}.
Każdy symulator generuje dane symulujące odczyty z określonego typu czujnika,
umieszczonego w określonym miejscu instalacji.

Dane są generowane w formacie JSON i zawierają informacje takie jak: identyfikator czujnika, typ, lokalizacja, znacznik czasu, wartość i
jednostka. Dane te są następnie publikowane na temat SNS \cite{sns_docs}, który działa jako punkt dystrybucji dla wielu subskrybentów.

\subsubsection{Przesyłanie danych do klastra}
\label{subsubsec:przesylanie_danych}

Dane opublikowane na temacie SNS są automatycznie dostarczane do kolejek SQS \cite{sqs_docs}, które są subskrybentami tematu. Kolejki SQS działają jako bufor między AWS a klastrem Kubernetes, zapewniając niezawodne dostarczanie wiadomości, nawet w przypadku tymczasowej niedostępności klastra.

W klastrze Kubernetes działa mikroserwis SQS-Kafka-Forwarder, który regularnie odpytuje kolejki SQS i pobiera nowe wiadomości. Wiadomości te są następnie deserializowane i publikowane na odpowiednie tematy Kafka, w zależności od typu czujnika i lokalizacji.

\subsubsection{Przetwarzanie strumieni danych}
\label{subsubsec:przetwarzanie_strumieni}

Dane opublikowane na tematach Kafka są przetwarzane przez mikroserwis \texttt{SparkDataProcessor}, który wykorzystuje Apache Spark (Spark Structured Streaming) \cite{spark_streaming} do analizy danych w czasie rzeczywistym. Przetwarzanie obejmuje:

\begin{itemize}
    \item \textbf{obliczanie średnich wartości} dla poszczególnych typów sensorów w zdefiniowanych oknach czasowych (moduł \texttt{MeanProcessor}),
    \item \textbf{wykrywanie zdarzeń} na podstawie przekroczenia zdefiniowanych progów ostrzegawczych i krytycznych (moduł \texttt{EventProcessor}),
    \item \textbf{predykcję ogólnego stanu technicznego} monitorowanego urządzenia na podstawie połączonych danych z wielu sensorów, przy użyciu modelu \texttt{RandomForestClassifier} (moduł \texttt{EquipmentStateProcessor}),
    \item \textbf{wzbogacanie oryginalnych danych} sensorycznych o przewidzianą etykietę stanu.
\end{itemize}

Wyniki przetwarzania, w formacie Avro, są publikowane na nowe, dedykowane tematy Kafka.

\subsubsection{Zapisywanie danych do bazy danych}
\label{subsubsec:zapisywanie_danych}

Przetworzone dane są konsumowane przez mikroserwis Kafka-DB-Forwarder, który zapisuje je do baz danych. Dane strukturalne, takie jak: odczyty czujników,
agregacje i metadane, są zapisywane do bazy danych PostgreSQL.

Zapisywanie danych do baz danych umożliwia ich późniejszą analizę, raportowanie i wizualizację, a także zapewnia trwałość danych.

\subsubsection{Udostępnianie danych przez API}
\label{subsubsec:udostepnianie_danych}

Zapisane dane są udostępniane przez mikroserwis Data-Service, który ekspozuje REST API do tworzenia i pobierania raportów. API to umożliwia:

\begin{itemize}
    \item \textbf{pobieranie danych surowych} - dostęp do nieprzetworzonych odczytów czujników,
    \item \textbf{pobieranie danych przetworzonych} - dostęp do agregacji, wykrytych anomalii, predykcji,
    \item \textbf{tworzenie raportów} - generowanie raportów na podstawie zadanych kryteriów,
    \item \textbf{pobieranie raportów} - dostęp do wcześniej wygenerowanych raportów.
\end{itemize}

API jest zabezpieczone mechanizmami uwierzytelniania i autoryzacji, implementowanymi przez mikroserwis Users-Service, który korzysta z Keycloak.

\subsubsection{Wizualizacja danych}
\label{subsubsec:wizualizacja_danych}

Ostatnim etapem przepływu danych jest ich wizualizacja na dashboardzie. Dashboard komunikuje się z API, pobierając dane do wyświetlenia, a następnie prezentuje je w formie wykresów, tabel i widżetów.

Dashboard umożliwia interaktywną eksplorację danych, filtrowanie, sortowanie i eksport wyników. Ponadto, dashboard może wyświetlać alerty i powiadomienia o wykrytych anomaliach i potencjalnych awariach.

Przepływ danych w projektowanym systemie zapewnia efektywne pozyskiwanie, przetwarzanie i analizę danych w czasie rzeczywistym, co jest kluczowe w kontekście monitorowania i optymalizacji procesu syntezy amoniaku. 