\section{Projekt systemu przetwarzania danych}
\label{sec:projekt_systemu}
\addcontentsline{lof}{section}{Rozdział \ref{sec:projekt_systemu}}
\addcontentsline{lol}{section}{Rozdział \ref{sec:projekt_systemu}}

W niniejszym rozdziale przedstawiono projekt autorskiego systemu do analizy danych w czasie rzeczywistym z systemów wieloczujnikowych, opartego na klastrze Kubernetes oraz narzędziach \mbox{Big Data}. Omówiono wymagania systemu, architekturę, model oraz przepływ informacji.

\subsection{Wymagania systemu osadzonego na klastrze Kubernetes}
\label{subsec:wymagania}

Na podstawie analizy literatury \ref{sec:przeglad_literatury} oraz istniejących rozwiązań, zidentyfikowano przedstawione poniżej wymagania dla projektowanego systemu.

\subsubsection{Wymagania funkcjonalne}
\label{subsubsec:wymagania_funkcjonalne}

\begin{itemize}
    \item \textbf{Pozyskiwanie danych} - system powinien umożliwiać pozyskiwanie informacji z różnych typów czujników, w tym:
   \begin{itemize}
       \item czujników temperatury,
       \item czujników ciśnienia,
       \item czujników przepływu,
       \item czujników drgań.
   \end{itemize}
    
    \item \textbf{Przetwarzanie danych} - system powinien umożliwiać przetwarzanie danych w czasie rzeczywistym, w tym:
    \begin{itemize}
        \item filtrację danych,
        \item agregację danych w różnych oknach czasowych,
        \item klasyfikację awarii,
        \item generowanie zdarzeń.
    \end{itemize}
    
    \item \textbf{Wizualizacja danych} - system powinien umożliwiać wizualizację danych w czasie rzeczywistym, w tym:
    \begin{itemize}
        \item wykresy liniowe,
        \item wskaźniki i mierniki,
        \item alerty i powiadomienia.
    \end{itemize}
    
   \item \textbf{Zarządzanie użytkownikami} - system powinien umożliwiać zarządzanie użytkownikami, w tym:
   \begin{itemize}
       \item logowanie użytkowników,
       \item różne poziomy uprawnień (admin, operator, gość),
       \item rejestrację użytkowników z poziomu panelu administracyjnego,
       \item kontrolę dostępu do informacji.
   \end{itemize}
    
    \item \textbf{Raportowanie} - system powinien umożliwiać generowanie raportów, w tym:
   \begin{itemize}
       \item tworzenie raportów dla dowolnej zakresu czasu,
       \item edycję raportów,
       \item wyszukiwanie raportów na podstawie różnych kryteriów.
   \end{itemize}
\end{itemize}

\newpage

\subsubsection{Wymagania niefunkcjonalne}
\label{subsubsec:wymagania_niefunkcjonalne}

\begin{itemize}
    
    \item \textbf{Skalowalność} - system powinien umożliwiać:
    \begin{itemize}
        \item skalowanie horyzontalne (dodawanie nowych węzłów),
        \item automatyczne skalowanie w zależności od obciążenia.
    \end{itemize}
    
    \item \textbf{Niezawodność} - system powinien charakteryzować się:
    \begin{itemize}
        \item odpornością na awarie pojedynczych komponentów.
    \end{itemize}
    
    \item \textbf{Bezpieczeństwo} - system powinien zapewniać:
    \begin{itemize}
        \item szyfrowanie informacji w spoczynku i w transporcie,
        \item uwierzytelnianie i autoryzację użytkowników,
        \item audytowanie dostępu do danych.
    \end{itemize}
    
    \item \textbf{Utrzymywalność} - system powinien charakteryzować się:
    \begin{itemize}
        \item modułową architekturą,
        \item dobrą dokumentacją,
        \item łatwością rozszerzania i modyfikacji.
    \end{itemize}
\end{itemize}

\newpage

\subsection{Architektura systemu}
\label{subsec:architektura}

Projektowany system opiera się na architekturze mikroserwisowej, wdrożonej na klastrze \textbf{Kubernetes} \cite{kubernetes_benefits}.
Architektura składa się z kilku kluczowych warstw, przedstawionych na rysunku \ref{Architektura systemu do analizy danych w czasie rzeczywistym}.

\singlesizedimageforced{images/architektura.png}{Uproszczona architektura systemu do analizy danych w czasie rzeczywistym}{1.0}

\singlesizedimageforced{images/cala_infra.png}{Architektura systemu do analizy danych w czasie rzeczywistym}{1.0}

\newpage

\subsubsection{Warstwa pozyskiwania danych}
\label{subsubsec:warstwa_pozyskiwania}

Warstwa pozyskiwania danych odpowiada za zbieranie danych z czujników i ich wstępne przetworzenie.
W projektowanym systemie dane są generowane przez symulatory czujników implementowane jako funkcje \textbf{AWS Lambda} (usługa obliczeń bezserwerowych firmy Amazon) \cite{aws_lambda_docs}.
Generują one dane symulujące odczyty z różnych typów czujników.

Dane generowane przez symulatory są formatowane jako wiadomości w formacie \textbf{JSON} (format wymiany danych) \cite{json_schema_org} i publikowane na tematy usługi \textbf{SNS} (usługa powiadomień firmy Amazon) \cite{sns_docs}, a następnie przenoszone do kolejek usługi \textbf{SQS} (usługa kolejkowania wiadomości firmy Amazon) \cite{sqs_docs}, stanowiących interfejs między \textbf{AWS} a klastrem \textbf{Kubernetes}.

\subsubsection{Warstwa komunikacji}
\label{subsubsec:warstwa_komunikacji}

Warstwa komunikacji odpowiada za odbieranie danych z warstwy pozyskiwania i ich dostarczanie do warstwy przetwarzania.
W projektowanym systemie warstwa ta opiera się na rozproszonej platformie do przetwarzania strumieniowego \mbox{Apache Kafka} \cite{kafka}.


Broker \mbox{Apache Kafka} zapewnia trwałość danych, wysoką przepustowość i skalowalność, co jest kluczowe w kontekście analizy danych w czasie rzeczywistym z wielu czujników.

\subsubsection{Warstwa przetwarzania}
\label{subsubsec:warstwa_przetwarzania}

Warstwa przetwarzania odpowiada za analizę danych w czasie rzeczywistym. W projektowanym systemie opiera się ona na frameworku \mbox{Apache Spark} (środowisko do obliczeń rozproszonych) \cite{spark_streaming}, wykorzystując jego moduł \mbox{Spark Structured Streaming} do przetwarzania strumieni. Głównym komponentem tej warstwy jest aplikacja \texttt{SparkDataProcessor}, zrealizowana w języku \textbf{Scala}. Zawiera ona logikę przetwarzania danych, podzieloną na wyspecjalizowane moduły takie jak: \texttt{MeanProcessor} (obliczanie średnich), \texttt{EventProcessor} (wykrywanie zdarzeń na podstawie progów) oraz \texttt{EquipmentStateProcessor} (predykcja stanu urządzenia przy użyciu modelu uczenia maszynowego \texttt{RandomForestClassifier} (algorytm klasyfikacji uczenia maszynowego)). Szczegółowy opis tych modułów oraz ich działania znajduje się w rozdziale \ref{sec:algorytmy_analizy}.

Silnik \mbox{Apache Spark} umożliwia przetwarzanie danych strumieniowych z wykorzystaniem zaawansowanych operacji, obsługę informacji opóźnionych (\textit{watermarks}), zarządzanie stanem oraz integrację z bibliotekami uczenia maszynowego (\mbox{Spark ML}), co jest kluczowe w kontekście kompleksowej analizy danych z systemów wieloczujnikowych.

\newpage

\singlesizedimageforced{images/spark_operator.png}{Działanie operatora dla silnika Spark z podami}{1.0}

\subsubsection{Warstwa składowania danych}
\label{subsubsec:warstwa_skladowania}

Warstwa składowania danych odpowiada za przechowywanie przetworzonych danych do dalszej analizy i wizualizacji. W ramach autorskiego systemu składa się ona z dwóch głównych komponentów:

\begin{itemize}
    \item \textbf{baza danych \texttt{PostgreSQL}} - relacyjna baza danych, przechowująca ustrukturyzowane dane, takie jak: odczyty czujników, metadane czy informacje o użytkownikach,
    \item \textbf{baza danych \texttt{Elasticsearch}} - baza danych \mbox{NoSQL} (nierelacyjna)~\cite{nosql_definition}, umożliwiająca szybkie wyszukiwanie i analizę danych, szczególnie przydatna w kontekście wykrywania anomalii i analizy trendów.
\end{itemize}

\subsubsection{Warstwa usług i interfejs API}
\label{subsubsec:warstwa_uslug}

Warstwa usług i interfejs API (interfejs programowania aplikacji) odpowiada za udostępnianie danych i funkcjonalności systemu zewnętrznym aplikacjom i użytkownikom. W ramach niniejszego opracowania składa się ona z kilku mikroserwisów:

\begin{itemize}
    \item \textbf{Data Service} - mikroserwis udostępniający interfejs API do dostępu do danych z czujników, umożliwiający tworzenie i pobieranie raportów,
    \item \textbf{Users Service} - mikroserwis zarządzający użytkownikami i uwierzytelnianiem, wykorzystujący serwer Keycloak jako system zarządzania tożsamością,
    \item \textbf{Front Service} - mikroserwis pełniący rolę \mbox{API Gateway} (bramy API)~\cite{api_gateway_definition}, wystawiający interfejs API innych mikroserwisów na zewnątrz klastra.
\end{itemize}

\singlesizedimageforced{images/home_api.png}{Interfejs API sekcji Home}{1.0}
\singlesizedimageforced{images/reports_api.png}{Interfejs API sekcji Reports}{1.0}

\subsubsection{Warstwa prezentacji}
\label{subsubsec:warstwa_prezentacji}

Warstwa prezentacji odpowiada za wizualizację danych i interakcję z użytkownikami.
W projektowanym systemie składa się ona z panelu sterowania, wyświetlającego informacje w formie wykresów, tabel i widżetów.

\vspace{0.3em}

Główne narzędzia panelu sterowania to:

\begin{itemize}
    \item \textbf{wykresy liniowe} - wizualizacja zmian parametrów w czasie,
    \item \textbf{wskaźniki i mierniki} - wizualizacja aktualnych wartości parametrów,
    \item \textbf{alerty} - powiadomienia o anomaliach i potencjalnych awariach,
    \item \textbf{raporty} - generowanie i przeglądanie raportów.
\end{itemize}

Panel sterowania jest implementowany jako aplikacja webowa, wykorzystująca bibliotekę React (biblioteka JavaScript do tworzenia interfejsów użytkownika) i biblioteki wizualizacji informacji.

\subsection{Model danych}
\label{subsec:model_danych}

Model danych projektowanego systemu składa się z kilku kluczowych encji, przedstawionych na rysunku \ref{Model danych systemu}.

\singlesizedimageforced{images/datamodel.png}{Model danych systemu}{0.8}

\subsubsection{Dane z czujników}
\label{subsubsec:dane_czujnikow}

Dane z czujników są modelowane jako strumienie zdarzeń, gdzie każde zdarzenie zawiera:

\begin{itemize}
    \item \textbf{typ czujnika} - rodzaj czujnika (temperatura, ciśnienie, przepływ, skład gazu, drgania),
    \item \textbf{znacznik lokalizacji} - miejsce, w którym znajduje się czujnik,
    \item \textbf{znacznik czasu} - czas, w którym dokonano pomiaru,
    \item \textbf{wartość} - wartość pomiaru,
    \item \textbf{jednostka} - jednostka, w której wyrażona jest wartość.
\end{itemize}

Dane te są serializowane przy użyciu formatu \mbox{Apache Avro} \cite{avro_documentation}, co zapewnia efektywne kodowanie i dekodowanie wiadomości.

\subsection{Model raportów w bazie Elasticsearch}
\label{subsec:model_raportow}

Baza danych Elasticsearch jest używany do przechowywania i szybkiego wyszukiwania raportów. Używa on algorytmów przeszukiwwania pełnotekstowego, które umożliwiają szybkie wyszukiwanie raportów po różnych parametrach. Po wysłaniu przez interfejs API zapytania do DataService, serwis ten wysyła zapytanie do bazy danych Elasticsearch, które zwraca raporty spełniające kryteria wyszukiwania. Reporty są przechowywane w bazie danych Elasticsearch w formacie JSON i są w specjalny sposób zindeksowane tak, by dane dało się bardzo szybko wyszukać. Raporty oraz zapytania są normalizowane do małych liter za pomocą normalizatora \texttt{lower\_case\_normalizer} oraz analizatora \texttt{lower\_case\_analyzer}. Model raportów został przedstawiony na listingu \ref{lst:model_raportow}.

\begin{lstlisting}[caption=Model raportów w bazie danych Elasticsearch, label={lst:model_raportow}]
    {
        "properties": {
                "id": {
                    "type": "keyword"
                },
                "label": {
                    "type": "keyword",
                    "normalizer": "lower_case_normalizer"
                },
                "name": {
                    "type": "text",
                    "fields": {
                        "lowercase": {
                            "type": "text",
                            "analyzer": "lower_case_analyzer"
                        },
                        "sort": {
                            "type": "keyword",
                            "normalizer": "lower_case_normalizer"
                        }
                    }
                },
                "description": {
                    "type": "text",
                    "fields": {
                        "lowercase": {
                            "type": "text",
                            "analyzer": "lower_case_analyzer"
                        }
                    }
                },
                "from": {
                    "type": "date",
                    "format": "epoch_millis"
                },
                "to": {
                    "type": "date",
                    "format": "epoch_millis"
                },
                "reportSensorLabels": {
                    "type": "nested",
                    "properties": {
                        "sensorType": {
                            "type": "keyword",
                            "normalizer": "lower_case_normalizer"
                        },
                        "label": {
                            "type": "keyword",
                            "normalizer": "lower_case_normalizer"
                        }
                    }
            }}}
    \end{lstlisting}


Analizatory i normalizatory używane w modelu raportów zostały przedstawione na listingu \ref{lst:analizatory_i_normalizatory}.

\begin{lstlisting}[caption=Analizatory i normalizatory w bazie danych Elasticsearch, label={lst:analizatory_i_normalizatory}]
    {
        "analysis": {
          "normalizer": {
            "lower_case_normalizer": {
              "type": "custom",
              "char_filter": [],
              "filter": [
                "lowercase"
              ]
            }
          },
          "analyzer": {
            "lower_case_analyzer": {
              "type": "custom",
              "tokenizer": "standard",
              "filter": [
                "lowercase"
              ]
            }
          }
        }
      }
\end{lstlisting}

\newpage

\subsubsection{Przetworzone dane}
\label{subsubsec:przetworzone_dane}

Przetworzone dane są wynikiem analizy danych surowych przez aplikację \texttt{SparkDataProcessor} i obejmują:

\begin{itemize}
    \item \textbf{Agregacje (Aggregations)} - średnie wartości oraz liczba odczytów dla poszczególnych typów sensorów, obliczane przez moduł \texttt{MeanProcessor} w zdefiniowanych oknach czasowych:
    \begin{itemize}
        \item \textit{sensor\_type} - typ sensora (np. "pressure", "temperature"),
        \item \textit{label} - etykieta urządzenia (np. "pump", "compressor"),
        \item \textit{window\_start} - początek okna czasowego,
        \item \textit{window\_end} - koniec okna czasowego,
        \item \textit{avg\_value} - średnia wartość pomiarów w oknie,
        \item \textit{count} - liczba pomiarów w oknie.
    \end{itemize}
    
    \item \textbf{Zdarzenia (Events)} - wykryte przez moduł \texttt{EventProcessor} przekroczenia zdefiniowanych progów ostrzegawczych i krytycznych dla danych sensorycznych:
    \begin{itemize}
        \item \textit{event\_id} - unikalny identyfikator zdarzenia,
        \item \textit{sensor\_type} - typ sensora, którego dotyczy zdarzenie,
        \item \textit{label} - etykieta urządzenia,
        \item \textit{timestamp} - czas wykrycia zdarzenia,
        \item \textit{title} - tytuł zdarzenia (np. "Przekroczenie progu krytycznego dla ciśnienia"),
        \item \textit{status} - status alertu (np. "Ostrzeżenie", "Krytyczny"),
        \item \textit{actual\_value} - rzeczywista wartość, która spowodowała zdarzenie.
    \end{itemize}
    
    \item \textbf{Dane wzbogacone o predykcję stanu (Augmented Data with Predicted Status)} - oryginalne dane sensoryczne wzbogacone o sklasyfikowany stan urządzenia, generowane przez moduł \texttt{EquipmentStateProcessor} z użyciem modelu \texttt{RandomForestClassifier}:
    \begin{itemize}
        \item \textit{original\_sensor\_data} - pełny zestaw oryginalnych informacji z sensora (np. ciśnienie, temperatura wraz ze znacznikiem czasu, typem urządzenia itp.),
        \item \textit{predicted\_status} - przewidziany stan urządzenia (np. "Stan normalny", "Wczesne zużycie", "Stan podkrytyczny", "Stan krytyczny", "Naprawa"),
        \item \textit{model\_type} - typ modelu użytego do predykcji (tutaj: \texttt{RandomForestClassifier}).
    \end{itemize}
\end{itemize}

Wszystkie te informacje są serializowane do formatu Avro i publikowane na dedykowane tematy Kafka. Następnie, wybrane wolumeny (np. zdarzenia, zagregowane dane do wizualizacji) mogą być zapisywane w bazach danych takich jak: PostgreSQL lub Elasticsearch przez dedykowane serwisy (np. \texttt{Kafka-DB-Forwarder}).

\newpage

\subsection{Przepływ danych w systemie}
\label{subsec:przeplyw_danych}

Przepływ danych w projektowanym systemie obejmuje kilka etapów, przedstawionych na rysunku \ref{Przepływ danych w systemie}.

\singlesizedimageforced{images/data_flow.png}{Przepływ danych w systemie}{0.8}

\subsubsection{Generowanie danych}
\label{subsubsec:generowanie_danych}

Proces rozpoczyna się od generowania danych przez symulatory czujników. Zostały one zaimplementowane jako funkcje AWS Lambda \cite{aws_lambda_docs},
wyzwalane periodycznie przez funckcje bezpośrednio osadzone na chmurze  \cite{aws_step_functions_docs}.
Każdy symulator generuje dane symulujące odczyty z określonego typu czujnika,
umieszczonego w określonym miejscu instalacji.

Dane są generowane w formacie JSON i zawierają informacje takie jak: identyfikator czujnika, typ, lokalizacja, znacznik czasu, wartość i
jednostka. Dane te są następnie publikowane na temat usługi SNS \cite{sns_docs}, działający jako punkt dystrybucji dla wielu subskrybentów.

\subsubsection{Przesyłanie danych do klastra}
\label{subsubsec:przesylanie_danych}

Dane opublikowane na temacie usługi SNS są automatycznie dostarczane do kolejek kolejkowania SQS \cite{sqs_docs}, będących subskrybentami tematu. Kolejki SQS działają jako bufor między chmurą AWS a klastrem Kubernetes, zapewniając niezawodne dostarczanie wiadomości, nawet w przypadku tymczasowej niedostępności klastra.

W klastrze Kubernetes działa mikroserwis SQS-Kafka-Forwarder, regularnie odpytujący kolejki kolejki SQS i pobierający nowe wiadomości. Wiadomości te są następnie deserializowane i publikowane na odpowiednie kanały (ang. topics) brokera Kafki, w zależności od typu czujnika i lokalizacji.

\subsubsection{Przetwarzanie strumieni danych}
\label{subsubsec:przetwarzanie_strumieni}

Dane opublikowane na kanałach brokera Kafki są przetwarzane przez mikroserwis \\ \texttt{SparkDataProcessor}, wykorzystujący silnik analityczny Apache Spark \mbox{(Spark Structured Streaming)} \cite{spark_streaming} do analizy danych w czasie rzeczywistym. 

\vspace{0.3em}

Przetwarzanie obejmuje:

\begin{itemize}
    \item \textbf{obliczanie średnich wartości} dla poszczególnych typów sensorów w zdefiniowanych oknach czasowych (moduł \texttt{MeanProcessor}),
    \item \textbf{wykrywanie zdarzeń} na podstawie przekroczenia zdefiniowanych progów ostrzegawczych i krytycznych (moduł \texttt{EventProcessor}),
    \item \textbf{predykcję ogólnego stanu technicznego} monitorowanego urządzenia na podstawie połączonych informacji z wielu sensorów, przy użyciu modelu \texttt{RandomForestClassifier} (moduł \texttt{EquipmentStateProcessor}),
    \item \textbf{wzbogacanie oryginalnych danych} sensorycznych o przewidzianą etykietę stanu.
\end{itemize}

Wyniki przetwarzania, w formacie Avro, są publikowane na nowe, dedykowane kanały brokera Kafki.

\subsubsection{Zapisywanie danych do bazy danych}
\label{subsubsec:zapisywanie_danych}

Przetworzone dane są konsumowane przez mikroserwis Kafka-DB-Forwarder, zapisujący je do baz danych. Dane strukturalne, takie jak: odczyty czujników,
agregacje i metadane, są zapisywane do bazy danych PostgreSQL.

Zapisywanie danych do baz danych umożliwia ich późniejszą analizę, raportowanie i wizualizację, a także zapewnia trwałość danych.

\subsubsection{Udostępnianie danych przez interfejs API}
\label{subsubsec:udostepnianie_danych}

Zapisane dane są udostępniane przez mikroserwis Data-Service, eksponujący interfejs REST API do tworzenia i pobierania raportów. 

\vspace{0.3em}

Interfejs API umożliwia:

\begin{itemize}
    \item \textbf{pobieranie danych surowych} - dostęp do nieprzetworzonych odczytów czujników,
    \item \textbf{pobieranie danych przetworzonych} - dostęp do agregacji, wykrytych anomalii, predykcji,
    \item \textbf{tworzenie raportów} - generowanie raportów na podstawie zadanych kryteriów,
    \item \textbf{pobieranie raportów} - dostęp do wcześniej wygenerowanych raportów.
\end{itemize}

Interfejs API jest zabezpieczone mechanizmami uwierzytelniania i autoryzacji, implementowanymi przez mikroserwis Users-Service, wykorzystujący serwer autoryzacyjny Keycloak.

\subsubsection{Wizualizacja analizowanych danych}
\label{subsubsec:wizualizacja_danych}

Ostatnim etapem przepływu informacji jest ich wizualizacja na ekranie zbiorczym (dashboard). Ekran zbiorczy komunikuje się z interfejsem API, pobierając dane do wyświetlenia, a następnie prezentuje je w formie wykresów, tabel i widżetów.

Ekran zbiorczy umożliwia interaktywną eksplorację danych, filtrowanie, sortowanie i eksport wyników. Ponadto, może on wyświetlać alerty i powiadomienia o wykrytych anomaliach i potencjalnych awariach.

Przepływ informacji w projektowanym systemie zapewnia efektywne pozyskiwanie, przetwarzanie i analizę danych w czasie rzeczywistym, co jest kluczowe w kontekście monitorowania i optymalizacji procesu syntezy amoniaku. 