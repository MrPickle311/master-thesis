\section{Projekt systemu przetwarzania danych w czasie rzeczywistym}
\label{sec:projekt_systemu}

W niniejszym rozdziale przedstawiono projekt systemu do analizy danych w czasie rzeczywistym z systemów wieloczujnikowych, opartego na klastrze Kubernetes oraz narzędziach Big Data. Omówiono wymagania systemu, architekturę, model oraz przepływ informacji.

\subsection{Wymagania systemu osadzonego na klastrze Kubernetes}
\label{subsec:wymagania}

Na podstawie analizy literatury \ref{sec:przeglad_literatury} oraz istniejących rozwiązań, zidentyfikowano przedstawione poniżej wymagania dla projektowanego systemu.

\subsubsection{Wymagania funkcjonalne}
\label{subsubsec:wymagania_funkcjonalne}

\begin{itemize}
    \item \textbf{Pozyskiwanie danych} - system powinien umożliwiać pozyskiwanie informacji z różnych typów czujników, w tym:
   \begin{itemize}
       \item czujników temperatury,
       \item czujników ciśnienia,
       \item czujników przepływu,
       \item czujników drgań.
   \end{itemize}
    
    \item \textbf{Przetwarzanie danych} - system powinien umożliwiać przetwarzanie danych w czasie rzeczywistym, w tym:
    \begin{itemize}
        \item filtrację danych,
        \item agregację danych w różnych oknach czasowych,
        \item klasyfikację awarii,
        \item generowanie zdarzeń.
    \end{itemize}
    
    \item \textbf{Wizualizacja danych} - system powinien umożliwiać wizualizację danych w czasie rzeczywistym, w tym:
    \begin{itemize}
        \item wykresy liniowe,
        \item wskaźniki i mierniki,
        \item alerty i powiadomienia.
    \end{itemize}
    
   \item \textbf{Zarządzanie użytkownikami} - system powinien umożliwiać zarządzanie użytkownikami, w tym:
   \begin{itemize}
       \item logowanie użytkowników,
       \item różne poziomy uprawnień (admin, operator, gość),
       \item rejestrację użytkowników z poziomu panelu administracyjnego,
       \item kontrolę dostępu do informacji. \newline
   \end{itemize}
    

    \item \textbf{Raportowanie} - system powinien umożliwiać generowanie raportów, w tym:
   \begin{itemize}
       \item tworzenie raportów dla dowolnej zakresu czasu,
       \item edycję raportów,
       \item wyszukiwanie raportów na podstawie różnych kryteriów.
   \end{itemize}
\end{itemize}

\subsubsection{Wymagania niefunkcjonalne}
\label{subsubsec:wymagania_niefunkcjonalne}

\begin{itemize}
    
    \item \textbf{Skalowalność} - system powinien umożliwiać:
    \begin{itemize}
        \item skalowanie horyzontalne (dodawanie nowych węzłów),
        \item automatyczne skalowanie w zależności od obciążenia.
    \end{itemize}
    
    \item \textbf{Niezawodność} - system powinien charakteryzować się:
    \begin{itemize}
        \item odpornością na awarie pojedynczych komponentów.
    \end{itemize}
    
    \item \textbf{Bezpieczeństwo} - system powinien zapewniać:
    \begin{itemize}
        \item szyfrowanie informacji w spoczynku i w transporcie,
        \item uwierzytelnianie i autoryzację użytkowników,
        \item audytowanie dostępu do danych.
    \end{itemize}
    
    \item \textbf{Utrzymywalność} - system powinien charakteryzować się:
    \begin{itemize}
        \item modułową architekturą,
        \item dobrą dokumentacją,
        \item łatwością rozszerzania i modyfikacji.
    \end{itemize}
\end{itemize}

\subsection{Architektura systemu}
\label{subsec:architektura}

Projektowany system opiera się na architekturze mikroserwisowej, wdrożonej na klastrze Kubernetes \cite{kubernetes_benefits}.
Architektura składa się z kilku kluczowych warstw, przedstawionych na rysunku \ref{Architektura systemu do analizy danych w czasie rzeczywistym}.

\singlesizedimageforced{images/architektura.png}{Uproszczone architektura systemu do analizy danych w czasie rzeczywistym}{1.0}

\singlesizedimageforced{images/cala_infra.png}{Architektura systemu do analizy danych w czasie rzeczywistym}{1.0}

\subsubsection{Warstwa pozyskiwania danych (symulatory czujników)}
\label{subsubsec:warstwa_pozyskiwania}

Warstwa pozyskiwania danych odpowiada za zbieranie danych z czujników i ich wstępne przetworzenie.
W projektowanym systemie dane są generowane przez symulatory czujników implementowane jako funkcje AWS Lambda \cite{aws_lambda_docs}.
Generują one dane symulujące odczyty z różnych typów czujników.

Dane generowane przez symulatory są formatowane jako wiadomości JSON \cite{json_schema_org} i publikowane na tematy SNS \cite{sns_docs}, a następnie przenoszone do kolejek SQS (Amazon Simple Queue Service, zarządzana usługa kolejkowania wiadomości), stanowiących interfejs między AWS a klastrem Kubernetes.

\subsubsection{Warstwa komunikacji (Apache Kafka)}
\label{subsubsec:warstwa_komunikacji}

Warstwa komunikacji odpowiada za odbieranie danych z warstwy pozyskiwania i ich dostarczanie do warstwy przetwarzania.
W projektowanym systemie warstwa ta opiera się na rozproszonej platformie do przetwarzania strumieniowego Apache Kafka \cite{kafka}.


Apache Kafka zapewnia trwałość danych, wysoką przepustowość i skalowalność, co jest kluczowe w kontekście analizy danych w czasie rzeczywistym z wielu czujników.

\subsubsection{Warstwa przetwarzania (Apache Spark)}
\label{subsubsec:warstwa_przetwarzania}

Warstwa przetwarzania odpowiada za analizę danych w czasie rzeczywistym. W projektowanym systemie warstwa ta opiera się na frameworku Apache Spark \cite{spark_streaming}, wykorzystując jego moduł Spark Structured Streaming do przetwarzania strumieni. Głównym komponentem tej warstwy jest aplikacja \texttt{SparkDataProcessor}, zrealizowana w języku Scala. Aplikacja ta zawiera logikę przetwarzania danych, podzieloną na wyspecjalizowane moduły takie jak: \texttt{MeanProcessor} (obliczanie średnich), \texttt{EventProcessor} (wykrywanie zdarzeń na podstawie progów) oraz \texttt{EquipmentStateProcessor} (predykcja stanu urządzenia przy użyciu modelu uczenia maszynowego RandomForestClassifier). Szczegółowy opis tych modułów oraz ich działania znajduje się w rozdziale \ref{sec:algorytmy_analizy}.

Apache Spark umożliwia przetwarzanie danych strumieniowych z wykorzystaniem zaawansowanych operacji, obsługę informacji opóźnionych (watermarks), zarządzanie stanem oraz integrację z bibliotekami uczenia maszynowego (Spark ML), co jest kluczowe w kontekście kompleksowej analizy danych z systemów wieloczujnikowych.

\singlesizedimageforced{images/spark_operator.png}{Działanie Spark Operatora z Driverami i aplikacją}{1.0}

\subsubsection{Warstwa składowania danych}
\label{subsubsec:warstwa_skladowania}

Warstwa składowania danych odpowiada za przechowywanie przetworzonych danych do dalszej analizy i wizualizacji. W projektowanym systemie warstwa ta składa się z dwóch głównych komponentów:

\begin{itemize}
    \item \textbf{PostgreSQL} - relacyjna baza danych, przechowująca ustrukturyzowane dane, takie jak: odczyty czujników, metadane czy informacje o użytkownikach,
    \item \textbf{Elasticsearch} - baza danych NoSQL \cite{nosql_definition}, umożliwiająca szybkie wyszukiwanie i analizę danych, szczególnie przydatna w kontekście wykrywania anomalii i analizy trendów.
\end{itemize}

\subsubsection{Warstwa usług i interfejs API}
\label{subsubsec:warstwa_uslug}

Warstwa usług i interfejs API odpowiada za udostępnianie danych i funkcjonalności systemu zewnętrznym aplikacjom i użytkownikom. W projektowanym systemie warstwa ta składa się z kilku mikroserwisów:

\begin{itemize}
    \item \textbf{Data Service} - mikroserwis udostępniający API do dostępu do danych z czujników, umożliwiający tworzenie i pobieranie raportów,
    \item \textbf{Users Service} - mikroserwis zarządzający użytkownikami i uwierzytelnianiem, wykorzystujący Keycloak jako system zarządzania tożsamością,
    \item \textbf{Front Service} - mikroserwis pełniący rolę API Gateway \cite{api_gateway_definition}, wystawiający interfejs API innych mikroserwisów na zewnątrz klastra.
\end{itemize}

Wszystkie mikroserwisy są implementowane jako aplikacje Spring Boot, co zapewnia łatwość rozwoju, testowania i wdrażania.

\singlesizedimageforced{images/home_api.png}{API sekcji Home}{1.0}
\singlesizedimageforced{images/reports_api.png}{API sekcji Reports}{1.0}

\subsubsection{Warstwa prezentacji}
\label{subsubsec:warstwa_prezentacji}

Warstwa prezentacji odpowiada za wizualizację danych i interakcję z użytkownikami.
W projektowanym systemie warstwa ta składa się z panelu sterowania, wyświetlającego informacje w formie wykresów, tabel i widżetów.

Główne narzędzia panelu sterowania to:

\begin{itemize}
    \item \textbf{wykresy liniowe} - wizualizacja zmian parametrów w czasie,
    \item \textbf{wskaźniki i mierniki} - wizualizacja aktualnych wartości parametrów,
    \item \textbf{alerty} - powiadomienia o anomaliach i potencjalnych awariach,
    \item \textbf{raporty} - generowanie i przeglądanie raportów.
\end{itemize}

Panel sterowania jest implementowany jako aplikacja webowa, wykorzystująca React i biblioteki wizualizacji informacji.

\subsection{Model danych}
\label{subsec:model_danych}

Model danych projektowanego systemu składa się z kilku kluczowych encji, przedstawionych na rysunku \ref{Model danych systemu}.

\singlesizedimageforced{images/datamodel.png}{Model danych systemu}{0.8}

\subsubsection{Dane z czujników}
\label{subsubsec:dane_czujnikow}

Dane z czujników są modelowane jako strumienie zdarzeń, gdzie każde zdarzenie zawiera:

\begin{itemize}
    \item \textbf{typ czujnika} - rodzaj czujnika (temperatura, ciśnienie, przepływ, skład gazu, drgania),
    \item \textbf{znacznik lokalizacji} - miejsce, w którym znajduje się czujnik,
    \item \textbf{znacznik czasu} - czas, w którym dokonano pomiaru,
    \item \textbf{wartość} - wartość pomiaru,
    \item \textbf{jednostka} - jednostka, w której wyrażona jest wartość.
\end{itemize}

Dane te są serializowane przy użyciu serializatora Apache Avro \cite{avro_documentation}, co zapewnia efektywne kodowanie i dekodowanie wiadomości.

\subsection{Model raportów w Elasticsearch}
\label{subsec:model_raportow}

Elasticsearch jest używany do przechowywania i szybkiego wyszukiwania raportów. Używa on algorytmów przeszukiwwania pełnotekstowego, które umożliwiają szybkie wyszukiwanie raportów po różnych parametrach. Po wysłaniu przez API zapytania do DataService, serwis ten wysyła zapytanie do Elasticsearch, które zwraca raporty spełniające kryteria wyszukiwania. Reporty są przechowywane w Elasticsearch w formacie JSON i są w specjalny sposób zindeksowane tak, by dane dało się bardzo szybko wyszukać. Raporty oraz zapytania są normalizowane do małych liter za pomocą normalizatora \texttt{lower\_case\_normalizer} oraz analizatora \texttt{lower\_case\_analyzer}.

\begin{lstlisting}[caption=Model raportów w Elasticsearch]
    {
        "properties": {
                "id": {
                    "type": "keyword"
                },
                "label": {
                    "type": "keyword",
                    "normalizer": "lower_case_normalizer"
                },
                "name": {
                    "type": "text",
                    "fields": {
                        "lowercase": {
                            "type": "text",
                            "analyzer": "lower_case_analyzer"
                        },
                        "sort": {
                            "type": "keyword",
                            "normalizer": "lower_case_normalizer"
                        }
                    }
                },
                "description": {
                    "type": "text",
                    "fields": {
                        "lowercase": {
                            "type": "text",
                            "analyzer": "lower_case_analyzer"
                        }
                    }
                },
                "from": {
                    "type": "date",
                    "format": "epoch_millis"
                },
                "to": {
                    "type": "date",
                    "format": "epoch_millis"
                },
                "reportSensorLabels": {
                    "type": "nested",
                    "properties": {
                        "sensorType": {
                            "type": "keyword",
                            "normalizer": "lower_case_normalizer"
                        },
                        "label": {
                            "type": "keyword",
                            "normalizer": "lower_case_normalizer"
                        }
                    }
            }
        }
    }
    \end{lstlisting}


\begin{lstlisting}[caption=Analizatory i normalizatory w Elasticsearch]
    {
        "analysis": {
          "normalizer": {
            "lower_case_normalizer": {
              "type": "custom",
              "char_filter": [],
              "filter": [
                "lowercase"
              ]
            }
          },
          "analyzer": {
            "lower_case_analyzer": {
              "type": "custom",
              "tokenizer": "standard",
              "filter": [
                "lowercase"
              ]
            }
          }
        }
      }
\end{lstlisting}

\subsubsection{Przetworzone dane}
\label{subsubsec:przetworzone_dane}

Przetworzone dane są wynikiem analizy danych surowych przez aplikację \texttt{SparkDataProcessor} i obejmują:

\begin{itemize}
    \item \textbf{Agregacje (Aggregations)} - średnie wartości oraz liczba odczytów dla poszczególnych typów sensorów, obliczane przez moduł \texttt{MeanProcessor} w zdefiniowanych oknach czasowych:
    \begin{itemize}
        \item \textit{sensor\_type} - typ sensora (np. "pressure", "temperature"),
        \item \textit{label} - etykieta urządzenia (np. "pump", "compressor"),
        \item \textit{window\_start} - początek okna czasowego,
        \item \textit{window\_end} - koniec okna czasowego,
        \item \textit{avg\_value} - średnia wartość pomiarów w oknie,
        \item \textit{count} - liczba pomiarów w oknie.
    \end{itemize}
    
    \item \textbf{Zdarzenia (Events)} - wykryte przez moduł \texttt{EventProcessor} przekroczenia zdefiniowanych progów ostrzegawczych i krytycznych dla danych sensorycznych:
    \begin{itemize}
        \item \textit{event\_id} - unikalny identyfikator zdarzenia,
        \item \textit{sensor\_type} - typ sensora, którego dotyczy zdarzenie,
        \item \textit{label} - etykieta urządzenia,
        \item \textit{timestamp} - czas wykrycia zdarzenia,
        \item \textit{title} - tytuł zdarzenia (np. "Przekroczenie progu krytycznego dla ciśnienia"),
        \item \textit{status} - status alertu (np. "Ostrzeżenie", "Krytyczny"),
        \item \textit{actual\_value} - rzeczywista wartość, która spowodowała zdarzenie.
    \end{itemize}
    
    \item \textbf{Dane wzbogacone o predykcję stanu (Augmented Data with Predicted Status)} - oryginalne dane sensoryczne wzbogacone o sklasyfikowany stan urządzenia, generowane przez moduł \texttt{EquipmentStateProcessor} z użyciem modelu \texttt{RandomForestClassifier}:
    \begin{itemize}
        \item \textit{original\_sensor\_data} - pełny zestaw oryginalnych informacji z sensora (np. ciśnienie, temperatura wraz ze znacznikiem czasu, typem urządzenia itp.),
        \item \textit{predicted\_status} - przewidziany stan urządzenia (np. "Stan normalny", "Wczesne zużycie", "Stan podkrytyczny", "Stan krytyczny", "Naprawa"),
        \item \textit{model\_type} - typ modelu użytego do predykcji (tutaj: \texttt{RandomForestClassifier}).
    \end{itemize}
\end{itemize}

Wszystkie te informacje są serializowane do formatu Avro i publikowane na dedykowane tematy Kafka. Następnie, wybrane wolumeny (np. zdarzenia, zagregowane dane do wizualizacji) mogą być zapisywane w bazach danych takich jak PostgreSQL lub Elasticsearch przez dedykowane serwisy (np. \texttt{Kafka-DB-Forwarder}).

\subsection{Przepływ danych w systemie}
\label{subsec:przeplyw_danych}

Przepływ danych w projektowanym systemie obejmuje kilka etapów, przedstawionych na rysunku \ref{Przepływ danych w systemie}.

\singlesizedimageforced{images/data_flow.png}{Przepływ danych w systemie}{0.8}

\subsubsection{Generowanie danych}
\label{subsubsec:generowanie_danych}

Proces rozpoczyna się od generowania danych przez symulatory czujników. Symulatory te są implementowane jako funkcje AWS Lambda \cite{aws_lambda_docs},
wyzwalane periodycznie przez funckcje bezpośrednio osadzone na chmurze  \cite{aws_step_functions_docs}.
Każdy symulator generuje dane symulujące odczyty z określonego typu czujnika,
umieszczonego w określonym miejscu instalacji.

Dane są generowane w formacie JSON i zawierają informacje takie jak: identyfikator czujnika, typ, lokalizacja, znacznik czasu, wartość i
jednostka. Dane te są następnie publikowane na temat SNS \cite{sns_docs}, działający jako punkt dystrybucji dla wielu subskrybentów.

\subsubsection{Przesyłanie danych do klastra}
\label{subsubsec:przesylanie_danych}

Dane opublikowane na temacie SNS są automatycznie dostarczane do kolejek SQS \cite{sqs_docs}, będących subskrybentami tematu. Kolejki SQS działają jako bufor między AWS a klastrem Kubernetes, zapewniając niezawodne dostarczanie wiadomości, nawet w przypadku tymczasowej niedostępności klastra.

W klastrze Kubernetes działa mikroserwis SQS-Kafka-Forwarder, regularnie odpytujący kolejki SQS i pobierający nowe wiadomości. Wiadomości te są następnie deserializowane i publikowane na odpowiednie kanały (ang. topics) Kafki, w zależności od typu czujnika i lokalizacji.

\subsubsection{Przetwarzanie strumieni danych}
\label{subsubsec:przetwarzanie_strumieni}

Dane opublikowane na kanałach Kafki są przetwarzane przez mikroserwis \texttt{SparkDataProcessor}, wykorzystujący silnik analityczny Apache Spark (Spark Structured Streaming) \cite{spark_streaming} do analizy danych w czasie rzeczywistym. Przetwarzanie obejmuje:

\begin{itemize}
    \item \textbf{obliczanie średnich wartości} dla poszczególnych typów sensorów w zdefiniowanych oknach czasowych (moduł \texttt{MeanProcessor}),
    \item \textbf{wykrywanie zdarzeń} na podstawie przekroczenia zdefiniowanych progów ostrzegawczych i krytycznych (moduł \texttt{EventProcessor}),
    \item \textbf{predykcję ogólnego stanu technicznego} monitorowanego urządzenia na podstawie połączonych informacji z wielu sensorów, przy użyciu modelu \texttt{RandomForestClassifier} (moduł \texttt{EquipmentStateProcessor}),
    \item \textbf{wzbogacanie oryginalnych danych} sensorycznych o przewidzianą etykietę stanu.
\end{itemize}

Wyniki przetwarzania, w formacie Avro, są publikowane na nowe, dedykowane kanały Kafka.

\subsubsection{Zapisywanie danych do bazy danych}
\label{subsubsec:zapisywanie_danych}

Przetworzone dane są konsumowane przez mikroserwis Kafka-DB-Forwarder, zapisujący je do baz danych. Dane strukturalne, takie jak: odczyty czujników,
agregacje i metadane, są zapisywane do bazy danych PostgreSQL.

Zapisywanie danych do baz danych umożliwia ich późniejszą analizę, raportowanie i wizualizację, a także zapewnia trwałość danych.

\subsubsection{Udostępnianie danych przez interfejs API}
\label{subsubsec:udostepnianie_danych}

Zapisane dane są udostępniane przez mikroserwis Data-Service, eksponujący REST API do tworzenia i pobierania raportów. API umożliwia:

\begin{itemize}
    \item \textbf{pobieranie danych surowych} - dostęp do nieprzetworzonych odczytów czujników,
    \item \textbf{pobieranie danych przetworzonych} - dostęp do agregacji, wykrytych anomalii, predykcji,
    \item \textbf{tworzenie raportów} - generowanie raportów na podstawie zadanych kryteriów,
    \item \textbf{pobieranie raportów} - dostęp do wcześniej wygenerowanych raportów.
\end{itemize}

API jest zabezpieczone mechanizmami uwierzytelniania i autoryzacji, implementowanymi przez mikroserwis Users-Service, wykorzystujący Keycloak.

\subsubsection{Wizualizacja analizowanych danych}
\label{subsubsec:wizualizacja_danych}

Ostatnim etapem przepływu informacji jest ich wizualizacja na dashboardzie (ekranie zbiorczym). Dashboard komunikuje się z interfejs API, pobierając dane do wyświetlenia, a następnie prezentuje je w formie wykresów, tabel i widżetów.

Dashboard umożliwia interaktywną eksplorację danych, filtrowanie, sortowanie i eksport wyników. Ponadto, dashboard może wyświetlać alerty i powiadomienia o wykrytych anomaliach i potencjalnych awariach.

Przepływ informacji w projektowanym systemie zapewnia efektywne pozyskiwanie, przetwarzanie i analizę danych w czasie rzeczywistym, co jest kluczowe w kontekście monitorowania i optymalizacji procesu syntezy amoniaku. 