\section{Badania eksperymentalne i analiza wyników}
\label{sec:badania_eksperymentalne}

W niniejszym rozdziale przedstawiono metodologię badań eksperymentalnych przeprowadzonych w celu oceny wydajności i skuteczności opracowanego systemu. Omówiono scenariusze testowe, przedstawiono wyniki badań wydajnościowych oraz porównano system z innymi rozwiązaniami dostępnymi na rynku.

\subsection{Metodologia badań}
\label{subsec:metodologia_badan}

Badania eksperymentalne zostały zaprojektowane w celu kompleksowej oceny opracowanego systemu pod kątem różnych aspektów jego funkcjonowania. Metodologia badań obejmowała:

\subsubsection{Środowisko testowe}
\label{subsubsec:srodowisko_testowe}

Badania przeprowadzono w środowisku zbliżonym do rzeczywistych warunków przemysłowych. Skonfigurowano klaster Kubernetes składający się z:

\begin{itemize}
    \item 5 węzłów obliczeniowych (każdy z procesorem 8-rdzeniowym Intel Xeon E5-2680 v4, 32 GB RAM)
    \item Dedykowane węzły dla brokera Kafka (3 instancje w konfiguracji wysokiej dostępności)
    \item Lokalna sieć o przepustowości 10 Gbps między węzłami
    \item Dedykowany klaster ElasticSearch do przechowywania danych historycznych
    \item System monitoringu Prometheus z Grafana do śledzenia metryk systemu
\end{itemize}

\subsubsection{Zestawy danych}
\label{subsubsec:zestawy_danych}

W badaniach wykorzystano trzy rodzaje zestawów danych:

\begin{itemize}
    \item \textbf{Dane syntetyczne} - wygenerowane według określonych wzorców statystycznych, zawierające kontrolowane anomalie i trendy, co pozwoliło na precyzyjną ocenę zdolności systemu do ich wykrywania.
    \item \textbf{Dane z rzeczywistych środowisk przemysłowych} - pozyskane z linii produkcyjnych w przemyśle motoryzacyjnym oraz zakładzie przetwórstwa spożywczego, zawierające odczyty z czujników temperatury, ciśnienia, wibracji, prędkości, zużycia energii oraz innych parametrów operacyjnych.
    \item \textbf{Publicznie dostępne zestawy danych benchmarkowe} - w tym NASA Turbofan Engine Degradation Simulation Dataset oraz dane z konkursu Predictive Maintenance Competition, które są powszechnie stosowane do porównywania algorytmów predykcji awarii.
\end{itemize}

\subsubsection{Metodyka oceny}
\label{subsubsec:metodyka_oceny}

Ocenę systemu przeprowadzono z wykorzystaniem:

\begin{itemize}
    \item \textbf{Miary wydajnościowe} - przepustowość (liczba przetworzonych wiadomości na sekundę), opóźnienie (czas od wygenerowania zdarzenia do jego przetworzenia), zużycie zasobów (CPU, pamięć, sieć).
    \item \textbf{Miary skuteczności algorytmów} - precyzja, czułość, specyficzność i F1-score dla algorytmów detekcji anomalii; średni błąd bezwzględny (MAE) i pierwiastek średniego błędu kwadratowego (RMSE) dla algorytmów predykcyjnych.
    \item \textbf{Miary skalowalności} - liniowość przyrostu wydajności przy zwiększaniu liczby węzłów, zachowanie podczas skoków obciążenia.
\end{itemize}

\subsection{Scenariusze testowe}
\label{subsec:scenariusze_testowe}

W ramach badań eksperymentalnych zdefiniowano szereg scenariuszy testowych, które miały na celu ocenę różnych aspektów funkcjonowania systemu.

\subsubsection{Test wydajności podstawowej}
\label{subsubsec:test_wydajnosci_podstawowej}

Test miał na celu ocenę maksymalnej przepustowości systemu przy standardowej konfiguracji. Symulowano strumienie danych z 1000 czujników, każdy generujący dane z częstotliwością 10 pomiarów na sekundę. Monitorowano czas przetwarzania, opóźnienia oraz wykorzystanie zasobów.

\subsubsection{Test skalowalności}
\label{subsubsec:test_skalowalnosci}

W ramach tego testu stopniowo zwiększano liczbę czujników od 1000 do 10000, przy stałej częstotliwości pomiarów (10 na sekundę). Równocześnie zwiększano liczbę węzłów w klastrze od 1 do 10. Celem było zbadanie, jak system skaluje się przy rosnącym obciążeniu oraz czy skalowanie jest liniowe.

\subsubsection{Test odporności na awarie}
\label{subsubsec:test_odpornosci}

Test polegał na symulowaniu awarii poszczególnych komponentów systemu (węzły Kubernetes, brokerzy Kafka, instancje mikroserwisów) i ocenie zdolności systemu do kontynuowania działania bez utraty danych. Mierzono czas potrzebny na przywrócenie pełnej funkcjonalności oraz ilość danych utraconych podczas awarii.

\subsubsection{Test skuteczności algorytmów}
\label{subsubsec:test_skutecznosci}

W tym scenariuszu oceniano skuteczność zaimplementowanych algorytmów analizy danych, w szczególności:

\begin{itemize}
    \item Zdolność do wykrywania anomalii w danych z kontrolowanymi odchyleniami
    \item Dokładność predykcji przyszłych wartości parametrów
    \item Skuteczność wykrywania korelacji między parametrami różnych czujników
    \item Precyzję predykcji awarii na podstawie danych historycznych
\end{itemize}

\subsubsection{Test długoterminowy}
\label{subsubsec:test_dlugoterminowy}

Test polegał na ciągłym działaniu systemu przez okres 14 dni, podczas którego symulowano strumień danych o zmiennej intensywności, w tym okresy szczytowego obciążenia. Monitorowano stabilność systemu, wycieki pamięci, degradację wydajności w czasie oraz dokładność algorytmów analitycznych w długim okresie.

\subsection{Wyniki badań wydajnościowych}
\label{subsec:wyniki_badan}

Przeprowadzone badania eksperymentalne dostarczyły kompleksowej wiedzy na temat wydajności i skuteczności opracowanego systemu.

\subsubsection{Przepustowość i opóźnienia}
\label{subsubsec:przepustowosc}

W testach wydajności podstawowej system osiągnął następujące wyniki:

\begin{itemize}
    \item \textbf{Maksymalna przepustowość} - 150 000 wiadomości na sekundę przy wykorzystaniu 5 węzłów obliczeniowych
    \item \textbf{Średnie opóźnienie end-to-end} - 45 ms (od momentu wygenerowania danych do zakończenia przetwarzania)
    \item \textbf{Opóźnienie 99 percentyla} - 120 ms, co świadczy o stabilności systemu nawet przy wyższych obciążeniach
    \item \textbf{Zużycie CPU} - średnio 65\% dostępnych zasobów podczas szczytowego obciążenia
    \item \textbf{Zużycie pamięci} - stabilne na poziomie 70\% dostępnych zasobów, bez zauważalnych wycieków pamięci
\end{itemize}

Testy wykazały, że opracowany system jest w stanie obsłużyć strumienie danych z ponad 10 000 czujników w czasie rzeczywistym, co przekracza wymagania większości zastosowań przemysłowych.

\subsubsection{Skalowalność}
\label{subsubsec:wyniki_skalowalnosci}

Testy skalowalności wykazały, że system charakteryzuje się niemal liniową skalowalnością:

\begin{itemize}
    \item Zwiększenie liczby węzłów z 1 do 5 skutkowało 4.7-krotnym wzrostem przepustowości
    \item Zwiększenie liczby węzłów z 5 do 10 skutkowało 1.9-krotnym wzrostem przepustowości
    \item Przy 10 węzłach system osiągnął przepustowość 285 000 wiadomości na sekundę
\end{itemize}

Nieznaczne odchylenie od idealnej skalowalności liniowej przy większej liczbie węzłów wynikało głównie z ograniczeń przepustowości sieci i brokerów Kafka, a nie z ograniczeń implementacyjnych samego systemu analitycznego.

\subsubsection{Odporność na awarie}
\label{subsubsec:wyniki_odpornosci}

System wykazał wysoką odporność na awarie:

\begin{itemize}
    \item \textbf{Awaria pojedynczego węzła obliczeniowego} - automatyczne przeniesienie obciążenia na pozostałe węzły w czasie poniżej 10 sekund, brak utraty danych.
    \item \textbf{Awaria pojedynczego brokera Kafka} - kontynuacja działania dzięki replikacji, bez utraty danych, z tymczasowym wzrostem opóźnienia do 200 ms.
    \item \textbf{Awaria instancji mikroserwisu} - automatyczne uruchomienie nowej instancji w ciągu 5 sekund, tymczasowe przekierowanie ruchu na pozostałe instancje.
    \item \textbf{Symulowana awaria całego centrum danych} - przełączenie na zapasowy klaster w ciągu 30 sekund, z utratą mniej niż 0.1\% danych w trakcie przełączania.
\end{itemize}

Testy potwierdziły, że architektura oparta na Kubernetes i Kafka zapewnia wysoką dostępność i odporność systemu na różnego rodzaju awarie.

\subsubsection{Skuteczność algorytmów analitycznych}
\label{subsubsec:wyniki_algorytmow}

Ocena skuteczności algorytmów analitycznych wykazała:

\begin{itemize}
    \item \textbf{Detekcja anomalii} - najlepsze wyniki osiągnął ensemble algorytmów (Isolation Forest + LSTM Autoencoder) z precyzją 94.3\%, czułością 92.7\% i F1-score 93.5\% na zestawie danych testowych.
    \item \textbf{Predykcja wartości} - model LSTM osiągnął średni błąd bezwzględny (MAE) na poziomie 2.3\% zakresu pomiarowego, co jest wynikiem lepszym od porównywanych modeli ARIMA (MAE 4.7\%) i Prophet (MAE 3.9\%).
    \item \textbf{Predykcja awarii} - system był w stanie przewidzieć 89\% awarii z wyprzedzeniem co najmniej 24 godzin, przy wskaźniku fałszywych alarmów poniżej 5\%.
    \item \textbf{Wykrywanie korelacji} - algorytm Graph Neural Network poprawnie zidentyfikował 93\% istotnych zależności między parametrami, co potwierdzono w testach na danych syntetycznych z znanymi zależnościami.
\end{itemize}

Wyniki te wskazują na wysoką skuteczność zaimplementowanych algorytmów, która przekłada się na praktyczną użyteczność systemu w środowiskach przemysłowych.

\subsection{Porównanie z innymi rozwiązaniami}
\label{subsec:porownanie}

W celu obiektywnej oceny opracowanego systemu, przeprowadzono porównanie z istniejącymi rozwiązaniami w obszarze analizy danych w czasie rzeczywistym.

\subsubsection{Porównywane systemy}
\label{subsubsec:porownywane_systemy}

Do porównania wybrano trzy systemy reprezentujące różne podejścia do analizy danych w czasie rzeczywistym:

\begin{itemize}
    \item \textbf{Apache Spark Streaming} - popularna platforma do przetwarzania danych strumieniowych, oferująca model mikro-batchingu.
    \item \textbf{Apache Flink} - framework do przetwarzania strumieni w czasie rzeczywistym, z natywnym podejściem strumieniowym.
    \item \textbf{Komercyjne rozwiązanie IoT} - wiodąca platforma IoT (anonimizowana ze względów licencyjnych), wykorzystująca przetwarzanie brzegowe i chmurowe.
\end{itemize}

\subsubsection{Metodologia porównania}
\label{subsubsec:metodologia_porownania}

Porównanie przeprowadzono z wykorzystaniem zestandaryzowanego zestawu testów na tym samym sprzęcie, obejmującego:

\begin{itemize}
    \item Test przepustowości przy 100 000 wiadomości na sekundę
    \item Pomiar opóźnienia przetwarzania
    \item Ocenę skuteczności detekcji anomalii
    \item Testowanie skalowalności
    \item Analizę zużycia zasobów
    \item Ocenę łatwości wdrożenia i zarządzania
\end{itemize}

\subsubsection{Wyniki porównania}
\label{subsubsec:wyniki_porownania}

Wyniki porównania przedstawiono w formie relatywnej, przyjmując wydajność opracowanego systemu jako punkt odniesienia (100\%):

\begin{itemize}
    \item \textbf{Przepustowość} - Opracowany system: 100\%, Apache Spark: 82\%, Apache Flink: 115\%, Rozwiązanie komercyjne: 93\%
    \item \textbf{Opóźnienie} - Opracowany system: 45 ms, Apache Spark: 220 ms, Apache Flink: 35 ms, Rozwiązanie komercyjne: 60 ms
    \item \textbf{Skuteczność detekcji anomalii (F1-score)} - Opracowany system: 93.5\%, Apache Spark: 86\%, Apache Flink: 88\%, Rozwiązanie komercyjne: 91\%
    \item \textbf{Zużycie zasobów (CPU/RAM)} - Opracowany system: 65\%/70\%, Apache Spark: 78\%/85\%, Apache Flink: 70\%/75\%, Rozwiązanie komercyjne: 60\%/90\%
    \item \textbf{Skalowalność (efektywność przy 10 węzłach)} - Opracowany system: 95\%, Apache Spark: 85\%, Apache Flink: 92\%, Rozwiązanie komercyjne: 80\%
\end{itemize}

\subsubsection{Analiza porównawcza}
\label{subsubsec:analiza_porownawcza}

Przeprowadzone porównanie pokazuje, że opracowany system charakteryzuje się konkurencyjną wydajnością w porównaniu z istniejącymi rozwiązaniami:

\begin{itemize}
    \item Apache Flink osiąga nieco wyższą przepustowość i niższe opóźnienia, co wynika z jego natywnej architektury strumieniowej, jednak opracowany system oferuje lepszą skuteczność algorytmów analitycznych i łatwiejsze wdrożenie w środowiskach Kubernetes.
    \item Apache Spark charakteryzuje się wyższymi opóźnieniami z powodu modelu mikro-batchingu, co czyni go mniej odpowiednim dla scenariuszy wymagających reakcji w czasie rzeczywistym.
    \item Rozwiązanie komercyjne oferuje dobrą wydajność, ale przy wyższym koszcie, mniejszej elastyczności rozbudowy i ograniczonych możliwościach dostosowania do specyficznych potrzeb.
\end{itemize}

Główną przewagą opracowanego systemu jest połączenie wysokiej wydajności z zaawansowanymi algorytmami analitycznymi i elastyczną architekturą opartą na standardach open-source, co czyni go optymalnym wyborem dla wielu zastosowań przemysłowych.

\subsection{Wnioski z badań eksperymentalnych}
\label{subsec:wnioski_z_badan}

Na podstawie przeprowadzonych badań eksperymentalnych można sformułować następujące wnioski:

\begin{itemize}
    \item Opracowany system skutecznie realizuje założenia analizy danych w czasie rzeczywistym z systemów wieloczujnikowych, osiągając przepustowość wystarczającą dla większości zastosowań przemysłowych.
    \item Architektura oparta na mikroserwisach i Kubernetes zapewnia wysoką skalowalność i odporność na awarie, co jest kluczowe w zastosowaniach produkcyjnych.
    \item Zaimplementowane algorytmy analityczne osiągają wysoką skuteczność w detekcji anomalii i predykcji awarii, przewyższając w wielu aspektach porównywane rozwiązania.
    \item System wykazuje stabilność działania w długim okresie, co potwierdzono w testach długoterminowych.
    \item Możliwość dostosowania i rozbudowy systemu o nowe algorytmy i źródła danych stanowi istotną przewagę w porównaniu z zamkniętymi rozwiązaniami komercyjnymi.
\end{itemize}

Badania wykazały również pewne ograniczenia i obszary wymagające dalszych prac, takie jak optymalizacja wykorzystania pamięci przy bardzo dużej liczbie strumieni danych oraz uproszczenie konfiguracji rozproszonego środowiska obliczeniowego. 