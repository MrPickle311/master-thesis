\section{Podsumowanie i wnioski}
\label{sec:podsumowanie_wnioski}
\addcontentsline{lof}{section}{Rozdział \ref{sec:podsumowanie_wnioski}}

Niniejsza praca magisterska koncentrowała się na zaprojektowaniu, implementacji oraz analizie systemu do przetwarzania i analizy danych strumieniowych, pochodzących z wieloczujnikowych systemów przemysłowych. Głównym jej celem było stworzenie kompleksowej platformy, nie tylko umożliwiającej zbieranie i agregację informacji, ale również ich zaawansowaną analizę, w tym detekcję anomalii i klasyfikację stanów awaryjnych urządzeń.

Kluczowym elementem pracy było opracowanie realistycznego \textbf{generatora danych} (rozdział \ref{sec:implementacja_generowania}), symulującego pracę urządzeń przemysłowych takich jak: pompy, sprężarki i turbiny. Generator ten, oparty na analizie statystycznej rzeczywistych danych oraz modelach matematycznych korelacji i stanów, został zaimplementowany w architekturze bezserwerowej chmury AWS, co zapewniło jego skalowalność i efektywność kosztową. Wygenerowane dane, odzwierciedlające parametry takie jak: temperatura, ciśnienie, wibracje i wilgotność, stanowiły podstawę do testowania i walidacji całego systemu.

Architektura opracowanego systemu (rozdział \ref{chap:konfiguracja_kubernetes}) została oparta na nowoczesnych technologiach konteneryzacji i orkiestracji, z wykorzystaniem klastra \textbf{Kubernetes} oraz menedżera pakietów \textbf{Helm} do zarządzania wdrożeniami. Zastosowano podejście mikrousługowe, gdzie poszczególne komponenty, takie jak: broker \textbf{Apache Kafka}, baza danych \textbf{Elasticsearch} do przechowywania i indeksowania informacji, relacyjna baza danych \textbf{PostgreSQL} do składowania danych i raportów oraz dedykowane usługi aplikacyjne (np. `FrontService` pełniący rolę bramy API, `data-service`, `users-service`) komunikują się ze sobą w ramach klastra. Istotną częścią oprogramowania jest również wtyczka do klastra Kubernetes \textbf{Spark Operator}, umożliwiający uruchamianie zadań przetwarzania informacji za pomocą silnika Apache Spark. Bezpieczeństwo i zarządzanie tożsamością w systemie zapewnia serwer \textbf{Keycloak} (rozdział \ref{chap:autoryzacja}), zintegrowany zarówno z komponentami backendowymi, jak i z interfejsem użytkownika stworzonym w technologii React. Uwierzytelnianie opiera się na tokenach JWT (ang. JSON Web Token).

W zakresie \textbf{algorytmów analizy danych} (rozdział \ref{sec:algorytm_analizy}), system implementuje mechanizmy agregacji czasowej danych oraz podstawowe metody statystyczne do detekcji anomalii. Kluczowym elementem analitycznym jest model predykcji stanu urządzenia oparty na klasyfikatorze \textbf{RandomForestClassifier} z biblioteki Spark MLlib, wytrenowany na danych historycznych z generatora. Rozważono również przyszłościowe rozszerzenia o bardziej zaawansowane techniki detekcji anomalii (np. Isolation Forest, One-Class SVM) oraz inne modele predykcyjne.

Potencjalne \textbf{zastosowania praktyczne} systemu (rozdział \ref{sec:zastosowania_praktyczne}) są szerokie i obejmują różne gałęzie przemysłu od motoryzacyjnego, przez energetyczny, po spożywczy. Głównymi korzyściami płynącymi z wdrożenia tego typu rozwiązań są, redukcja nieplanowanych przestojów dzięki konserwacji predykcyjnej, optymalizacja procesów produkcyjnych oraz ogólne zwiększenie efektywności operacyjnej i bezpieczeństwa. Analiza ekonomiczna, choć w kontekście prototypu ma charakter szacunkowy, wskazuje na istotny potencjał zwrotu z inwestycji.


Do głównych \textbf{osiągnięć} niniejszej pracy należy zaliczyć:
\begin{itemize}
    \item zaprojektowanie i implementacja w pełni funkcjonalnego, zintegrowanego systemu do analizy danych  strumeniowych, obejmującego generowanie informacji, ich przesyłanie, przetwarzanie, przechowywanie, analizę i wizualizację (choć sama wizualizacja nie była głównym przedmiotem opisu w tej pracy, jej istnienie jest implikowane przez architekturę i opisywane komponenty klienckie),
    \item skuteczne połączenie różnorodnych technologii (funkcja AWS Lambda, platforma Docker, klaster Kubernetes, menedżer pakietów Helm, broker Kafka, silnik analityczny Spark, baza danych Elasticsearch, framework Spring Boot, biblioteka React, serwer autoryzacji Keycloak) w spójną i skalowalną architekturę,
    \item opracowanie realistycznego, konfigurowalnego generatora danych przemysłowych,
    \item implementacja potoku przetwarzania i analizy danych z wykorzystaniem modeli uczenia maszynowego do predykcji stanu urządzeń,
    \item zapewnienie bezpieczeństwa systemu poprzez mechanizmy autoryzacji i uwierzytelniania.
\end{itemize}

Praca ta stanowi przyczynek do rozwoju systemów Przemysłowego Internetu Rzeczy (IIoT) i analityki predykcyjnej. \textbf{Ograniczenia} obecnego rozwiązania obejmują między innymi uproszczenia w niektórych modelach analitycznych oraz fakt, że system był testowany głównie na danych syntetycznych. 

Dalsze badania i rozwój mogłyby koncentrować się na:
\begin{itemize}
    \item walidacji systemu na rzeczywistych danych przemysłowych z większej liczby zróżnicowanych instalacji,
    \item implementacji i ewaluacji bardziej zaawansowanych algorytmów detekcji anomalii i modeli predykcyjnych, w tym technik uczenia głębokiego (np. sieć LSTM) oraz metod XAI (ang. Explainable AI) zwiększających transparentność decyzji modeli,
    \item rozbudowie systemu o moduły optymalizacji parametrów pracy urządzeń w oparciu o predykcje wartości danych z czuników,
    \item eksploracji zastosowań metodologii przechowywania danych bliżej klientów \textit{edge computing} do wstępnego przetwarzania danych bliżej ich źródła,
    \item rozwoju koncepcji Cyfrowego Bliźniaka (Digital Twin) w oparciu o zgromadzone dane i modele,
    \item rozszerzeniu możliwości interfejsu użytkownika o bardziej zaawansowane wizualizacje i narzędzia analityczne dla operatorów.
\end{itemize}

Podsumowując, opracowany w ramach niniejszej pracy system demonstruje możliwości efektywnego wykorzystania nowoczesnych technologii informatycznych do rozwiązywania złożonych problemów analizy danych w przemyśle. Stanowi on solidną podstawę do dalszych badań i rozwoju w kierunku inteligentnych systemów monitorowania i zarządzania procesami produkcyjnymi. 