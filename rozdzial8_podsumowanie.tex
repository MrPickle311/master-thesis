\section{Podsumowanie i wnioski}
\label{sec:podsumowanie_wnioski}

Niniejsza praca magisterska koncentrowała się na zaprojektowaniu, implementacji oraz analizie autorskiego systemu do przetwarzania i analizy danych strumieniowych, pochodzących z wieloczujnikowych systemów przemysłowych. Głównym jej celem było stworzenie kompleksowej platformy, nie tylko umożliwiającej zbieranie i agregację informacji, ale również ich zaawansowaną analizę, w tym detekcję anomalii i klasyfikację stanów awaryjnych urządzeń.

Kluczowym elementem pracy było opracowanie realistycznego \textit{generatora danych} (rozdział \ref{sec:implementacja_generowania}), symulującego pracę urządzeń przemysłowych takich jak: pompy, sprężarki i turbiny. Został on oparty na analizie statystycznej rzeczywistych danych oraz modelach matematycznych korelacji i stanów, a następnie zaimplementowany w architekturze bezserwerowej chmury \textit{AWS}, co zapewniło jego skalowalność i efektywność kosztową. Wygenerowane dane, odzwierciedlające parametry takie jak: temperatura, ciśnienie, wibracje i wilgotność, stanowiły podstawę do testowania i walidacji całego systemu.

Architektura opracowanego systemu (rozdział \ref{chap:konfiguracja_kubernetes}) została oparta na nowoczesnych technologiach konteneryzacji i orkiestracji, z wykorzystaniem klastra \textit{Kubernetes} oraz menedżera pakietów \textit{Helm} do zarządzania wdrożeniami. Zastosowano podejście mikrousługowe, gdzie poszczególne komponenty, takie jak: broker \textit{Apache Kafka}, baza danych \textit{Elasticsearch} do przechowywania i indeksowania informacji, relacyjna baza danych \textit{PostgreSQL} do składowania danych i raportów oraz dedykowane usługi aplikacyjne (np. `FrontService` pełniący rolę bramy API, `data-service`, `users-service`) komunikują się ze sobą w ramach klastra. Istotną częścią oprogramowania jest również wtyczka do klastra Kubernetes \textit{Spark Operator}, umożliwiający uruchamianie zadań przetwarzania informacji za pomocą silnika \mbox{\textit{Apache Spark}}. Bezpieczeństwo i zarządzanie tożsamością w opracowanym systemie zapewnia serwer \textit{Keycloak} (rozdział \ref{chap:autoryzacja}), zintegrowany zarówno z komponentami back-endowymi, jak i z interfejsem użytkownika stworzonym w technologii React. Uwierzytelnianie opiera się na tokenach JWT (ang. \mbox{\textit{JSON Web Token}}).

W zakresie \textit{algorytmów analizy danych} (rozdział \ref{sec:algorytmy_analizy}), zaimplementowany system wykorzystuje mechanizmy agregacji czasowej danych oraz podstawowe metody statystyczne do detekcji anomalii. Kluczowym elementem analitycznym jest model predykcji stanu urządzenia oparty na klasyfikatorze \textit{RandomForestClassifier} z biblioteki Spark MLlib, wytrenowany na danych historycznych z generatora. Rozważono również przyszłościowe rozszerzenia o bardziej zaawansowane techniki detekcji anomalii (np. Isolation Forest, One-Class SVM) oraz inne modele predykcyjne.

Potencjalne \textit{zastosowania praktyczne} systemów podobnych do opisanego w niniejszej pracy (rozdział \ref{sec:zastosowania_praktyczne}) są szerokie i obejmują różne gałęzie przemysłu od motoryzacyjnego, przez energetyczny, po spożywczy. Głównymi korzyściami płynącymi z wdrożenia tego typu rozwiązań są: redukcja nieplanowanych przestojów dzięki konserwacji predykcyjnej, optymalizacja procesów produkcyjnych oraz ogólne zwiększenie efektywności operacyjnej i bezpieczeństwa. Analiza ekonomiczna, mająca tu charakter bardzo pobieżny i szacunkowy, wskazuje na istotny potencjał zwrotu z inwestycji.

\vspace{0.3em}

Do głównych osiągnięć niniejszej pracy należy zaliczyć:
\begin{itemize}
    \item zaprojektowanie i implementacja w pełni funkcjonalnego, zintegrowanego systemu do analizy danych  strumeniowych, obejmującego generowanie informacji, ich przesyłanie, przetwarzanie, przechowywanie, analizę i wizualizację (choć sama wizualizacja nie była głównym przedmiotem opisu w tej pracy, jej istnienie jest implikowane przez architekturę i opisywane komponenty klienckie),
    \item skuteczne połączenie różnorodnych technologii (funkcja \textit{AWS Lambda}, platforma \textit{Docker}, klaster \textit{Kubernetes}, menedżer pakietów \textit{Helm}, broker \mbox{\textit{Apache Kafka}}, silnik analityczny \\ \mbox{\textit{Apache Spark}}, baza danych \textit{Elasticsearch}, framework \mbox{\textit{Spring Boot}}, biblioteka \textit{React}, serwer autoryzacji \textit{Keycloak}) w spójną i skalowalną architekturę,
    \item opracowanie realistycznego, konfigurowalnego generatora danych przemysłowych,
    \item implementacja potoku przetwarzania i analizy danych z wykorzystaniem modeli uczenia maszynowego do predykcji stanu urządzeń,
    \item zapewnienie bezpieczeństwa systemu poprzez mechanizmy autoryzacji i uwierzytelniania.
\end{itemize}

\vspace{0.3em}

Wykonana praca może stanowić podstawę do rozwoju systemów Przemysłowego \mbox{\textit{Internetu Rzeczy}} (\mbox{\textit{IIoT}} - \mbox{\textit{Industrial Internet of Things}}) i analityki predykcyjnej. \textit{Ograniczenia} obecnego rozwiązania obejmują między innymi uproszczenia w niektórych modelach analitycznych oraz fakt, że opracowany system był testowany głównie na danych syntetycznych. 

\vspace{0.3em}

Dalsze badania i rozwój mogą koncentrować się na:
\begin{itemize}
    \item walidacji systemu na rzeczywistych danych przemysłowych z większej liczby zróżnicowanych instalacji,
    \item implementacji i ewaluacji bardziej zaawansowanych algorytmów detekcji anomalii i modeli predykcyjnych, w tym technik uczenia głębokiego (np. sieć \textit{LSTM} - \mbox{\textit{Long Short-Term Memory}}) oraz metod \mbox{\textit{XAI}} (\mbox{\textit{Explainable AI}} - wyjaśnialne sztuczne inteligencje) zwiększających transparentność decyzji modeli,
    \item rozbudowie systemu o moduły optymalizacji parametrów pracy urządzeń w oparciu o predykcje wartości danych z czuników,
    \item eksploracji zastosowań metodologii przechowywania danych bliżej klientów \textit{edge computing} do wstępnego przetwarzania danych bliżej ich źródła,
    \item rozwoju koncepcji Cyfrowego Bliźniaka (Digital Twin) w oparciu o zgromadzone dane i modele,
    \item rozszerzeniu możliwości interfejsu użytkownika o bardziej zaawansowane wizualizacje i narzędzia analityczne dla operatorów.
\end{itemize}

\vspace{0.3em}

Podsumowując, opracowany w ramach niniejszej pracy system demonstruje możliwości efektywnego wykorzystania nowoczesnych technologii informatycznych do rozwiązywania złożonych problemów analizy danych w przemyśle. Stanowi on solidną podstawę do dalszych badań i rozwoju w kierunku inteligentnych systemów monitorowania i zarządzania procesami produkcyjnymi. 