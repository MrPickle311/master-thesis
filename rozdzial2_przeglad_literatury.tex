\section{Przegląd literatury i stan wiedzy}
\label{sec:przeglad_literatury}

Niniejszy rozdział przedstawia przegląd literatury oraz aktualny stan wiedzy w dziedzinach kluczowych dla realizacji celów pracy. Omówione zostaną zagadnienia związane z analizą danych w czasie rzeczywistym, architekturami systemów rozproszonych, ze szczególnym uwzględnieniem mikroserwisów i konteneryzacji, a także narzędziami Big Data wykorzystywanymi do przetwarzania i analizy dużych wolumenów informacji.

\subsection{Analiza danych w czasie rzeczywistym}
\label{subsec:analiza_danych}

Analiza danych w czasie rzeczywistym (ang. \mbox{Real-Time Analytics}) odnosi się do procesów i technologii umożliwiających analizowanie danych natychmiast po ich wygenerowaniu lub zebraniu \cite{realtime_analytics}. Głównym celem jest uzyskanie natychmiastowych wniosków i reakcja na zdarzenia w możliwie najkrótszym czasie. Odróżnia to analizę w czasie rzeczywistym od tradycyjnego przetwarzania wsadowego (ang. batch processing), gdzie dane są gromadzone przez pewien okres i analizowane później \cite{data_processing_models}.

\vspace{0.3em}

Kluczowe aspekty analizy danych w czasie rzeczywistym to:

\begin{itemize}
    \item \textbf{niskie opóźnienia (ang. Low Latency)}, oznaczające minimalny czas od momentu pojawienia się danych do momentu uzyskania wyników analizy,
    \item \textbf{wysoka przepustowość (ang. High Throughput)}, czyli zdolność systemu do przetwarzania dużej liczby zdarzeń lub transakcji w jednostce czasu,
    \item \textbf{ciągłe przetwarzanie (ang. Continuous Processing)}, gdzie dane są analizowane w sposób ciągły, a nie w odizolowanych partiach.
\end{itemize}

\vspace{0.3em}

W kontekście analizy danych z systemów wieloczujnikowych szczególnie istotne jest przetwarzanie strumieniowe, umożliwiające szybką reakcję na zmieniające się warunki procesu produkcyjnego.

\subsubsection{Wyzwania w analizie danych strumieniowych}
\label{subsubsec:wyzwania_analizy_rt}

Analiza danych strumieniowych, choć oferuje wiele korzyści, stawia przed projektantami systemów szereg istotnych wyzwań technicznych - przedstawionych poniżej:

\begin{itemize}
    \item \textbf{Duża objętość i wysoka szybkość danych} - systemy czasu rzeczywistego powinny obsługiwać ogromne ilości informacji napływających z wysoką szybkością. Wymaga to wydajnej infrastruktury zdolnej do przetwarzania wolumenów z minimalnym opóźnieniem. Rozwiązaniem jest wykorzystanie systemów rozproszonych, optymalizacja algorytmów oraz efektywne zarządzanie zasobami.
    
    \item \textbf{Wymóg niskich opóźnień} - aplikacje czasu rzeczywistego wymagają niemal natychmiastowego przetwarzania danych i generowania odpowiedzi. Opóźnienia mogą prowadzić do dezaktualizacji wyników i nieprawidłowych decyzji. Kluczowe jest zastosowanie przetwarzania w pamięci operacyjnej (zarezerwowanej dla aplikacji), optymalizacji zapytań i minimalizacji operacji wejścia/wyjścia.
    
    \item \textbf{Spójność i dokładność danych} - utrzymanie spójności danych podczas ich przetwarzania jest krytyczne dla poprawności analizy. Systemy powinny zapewnić dokładną semantykę przetwarzania (exactly-once processing) i obsługę braku uporządkowania czasowego w danych.
    
    \newpage

    \item \textbf{Odporność na awarie i niezawodność} - systemy analizy czasu rzeczywistego powinny działać nieprzerwanie, nawet w przypadku awarii poszczególnych komponentów. Wymagane są mechanizmy automatycznego odzyskiwania po awarii, replikacji danych i równoważenia obciążenia.
    
    \item \textbf{Przetwarzanie złożonych zdarzeń} - wykrywanie wzorców i korelacji w strumieniach danych wymaga zaawansowanych technik przetwarzania zdarzeń. Konieczne jest zastosowanie algorytmów \textit{CEP} (ang. Complex Event Processing) \cite{luckham2002power} zdolnych do identyfikacji istotnych wzorców w czasie rzeczywistym.
    
    \item \textbf{Integracja z istniejącymi systemami} - nowe rozwiązania powinny współpracować z istniejącą infrastrukturą IT (ang. Information Technology) \cite{tanenbaum2011computer}. Wymaga to wykorzystania standardowych interfejsów i brokerów wiadomości.
    
    \item \textbf{Skalowalność} - systemy powinny płynnie dostosowywać się do zmieniających się wolumenów danych i wzorców ruchu. Kluczowe jest projektowanie architektury umożliwiającej poziome skalowanie oraz elastyczne przydzielanie zasobów.
    
    \item \textbf{Bezpieczeństwo i prywatność} - ochrona wrażliwych danych podczas przetwarzania w czasie rzeczywistym stanowi istotne wyzwanie. Systemy powinny implementować szyfrowanie, kontrolę dostępu oraz mechanizmy audytu, zapewniając jednocześnie zgodność z przepisami dotyczącymi ochrony informacji.
\end{itemize}

\vspace{0.3em}

Skuteczne rozwiązanie tych wyzwań wymaga starannego projektowania architektury systemu, doboru odpowiednich technologii oraz uwzględnienia specyficznych wymagań aplikacji. W kolejnych rozdziałach omówione zostaną narzędzia i techniki pozwalające sprostać tym wyzwaniom.

\subsection{Systemy wieloczujnikowe w przemyśle}
\label{subsec:systemy_wieloczujnikowe}

Systemy wieloczujnikowe to zbiory urządzeń pomiarowych, monitorujących różne parametry procesów przemysłowych \cite{multisensor_systems}.
W nowoczesnych zakładach produkcyjnych, systemy te generują ogromne ilości danych, które odpowiednio przetworzone mogą dostarczyć cennych informacji na temat stanu procesu.

\subsubsection{Rodzaje czujników przemysłowych}
\label{subsubsec:rodzaje_czujnikow}

W przemyśle wykorzystuje się różne rodzaje czujników, odnoszące się do różnych wielkości fizycznych, takich jak:

\begin{itemize}
    \item \textbf{czujniki temperatury} - monitorują temperaturę w różnych punktach instalacji,
    \item \textbf{czujniki ciśnienia} - mierzą ciśnienie gazu lub cieczy w instalacji,
    \item \textbf{czujniki przepływu} - monitorują przepływ cieczy i gazów przez instalację,
    \item \textbf{czujniki składu gazu} - analizują skład mieszanin gazowych, np. zawartość wodoru, azotu, amoniaku, tlenu czy dwutlenku węgla,
    \item \textbf{czujniki drgań i hałasu} - monitorują drgania i hałas generowane przez urządzenia, co może wskazywać na potencjalne problemy.
\end{itemize}

\newpage

\subsubsection{Architektura systemów wieloczujnikowych}
\label{subsubsec:architektura_systemow}

Tradycyjne systemy wieloczujnikowe opierają się na architekturze trójwarstwowej:

\begin{itemize}
    \item \textbf{warstwa czujników} - obejmuje czujniki fizyczne wraz z konwerterami analogowo-cyfrowymi,
    \item \textbf{warstwa komunikacji} - odpowiada za przesyłanie danych z czujników do warstwy przetwarzania,
    \item \textbf{warstwa przetwarzania} - przetwarza dane z czujników i udostępnia je użytkownikom lub innym systemom.
\end{itemize}

\vspace{0.3em}

W nowoczesnych systemach warstwa komunikacji często wykorzystuje technologie IoT, takie jak: technologia \textit{MQTT} (protokół komunikacyjny dla urządzeń IoT) \cite{ietf_mqtt_v5}, \textit{AMQP} (protokół kolejkowania wiadomości) \cite{amqp_v1} czy \textit{OPC UA} (standard komunikacji przemysłowej) \cite{opc_ua_spec},
a warstwa przetwarzania opiera się na mechanizmach przetwarzania strumieniowego, takich jak:

\begin{itemize}
    \item broker \mbox{Apache Kafka} \cite{kafka},
    \item platforma \mbox{Apache Flink} (środowisko do obliczeń strumieniowych) \cite{flink}.
\end{itemize}

\subsection{Przedstawienie architektury mikroserwisowej}
\label{subsec:architektura_mikroserwisowa}

Architektura mikroserwisowa to podejście do tworzenia aplikacji jako zbioru luźno powiązanych, małych, autonomicznych usług,
komunikujących się ze sobą za pomocą mechanizmów, takich jak: protokół HTTP (ang. Hypertext Transfer Protocol) \cite{rfc_http1_1, microservice_architecture}.
Każdy mikroserwis realizuje określoną funkcjonalność biznesową i może być rozwijany, wdrażany i skalowany niezależnie od innych usług.

\subsubsection{Zalety architektury mikroserwisowej}
\label{subsubsec:zalety_mikroserwisow}

Architektura mikroserwisowa oferuje szereg zalet w kontekście systemów do analizy danych w czasie rzeczywistym \cite{microservice_benefits}:

\begin{itemize}
    \item \textbf{skalowalność} - możliwość niezależnego skalowania poszczególnych usług w zależności od obciążenia,
    \item \textbf{odporność na awarie} - awaria jednego mikroserwisu nie powoduje awarii całego systemu,
    \item \textbf{elastyczność technologiczna} - możliwość wykorzystania różnych technologii i języków programowania w różnych mikroserwisach,
    \item \textbf{szybsze wdrażanie} - możliwość niezależnego wdrażania poszczególnych mikroserwisów,
    \item \textbf{łatwiejsze zarządzanie kodem} - mniejsze, bardziej zrozumiałe bazy kodu dla poszczególnych usług.
\end{itemize}

\subsubsection{Wyzwania architektury mikroserwisowej}
\label{subsubsec:wyzwania_mikroserwisow}

Architektura mikroserwisowa stawia również pewne wyzwania, takie jak: \cite{microservice_challenges}:

\begin{itemize}
    \item \textbf{złożoność operacyjna} - zarządzanie wieloma niezależnymi usługami może być skomplikowane,
    \item \textbf{spójność danych} - z uwagi na trudności w utrzymaniu spójności danych między różnymi mikroserwisami,
    \item \textbf{koszty komunikacji sieciowej} - komunikacja między mikroserwisami wprowadza dodatkowe opóźnienia,
    \item \textbf{testowanie end-to-end} - z uwagi na trudności w testowaniu całego systemu złożonego z wielu niezależnych usług.
\end{itemize}

\subsection{Kubernetes jako platforma orkiestracji kontenerów}
\label{subsec:kubernetes}

Kubernetes to otwarta platforma do orkiestracji kontenerów, automatyzująca wdrażanie, skalowanie i zarządzanie aplikacjami
kontenerowymi \cite{kubernetes}. Powstała jako projekt Google, obecnie rozwijana przez \textit{Cloud Native Computing Foundation} \cite{cncf_website}.

\subsubsection{Podstawowe koncepcje platformy Kubernetes}
\label{subsubsec:podstawy_kubernetes}

Platforma Kubernetes bazuje na kilku kluczowych koncepcjach \cite{kubernetes_concepts}:

\begin{itemize}
    \item \textbf{pod} - najmniejsza jednostka wdrożeniowa w Kubernetes, składająca się z jednego lub więcej kontenerów,
    \item \textbf{deployment} - opakowanie na pody określające ich pożądany stan, umożliwiając ich skalowanie i aktualizacje,
    \item \textbf{service} - abstrakcja definiująca logiczny zestaw podów i politykę dostępu do nich,
    \item \textbf{ingress} - abstrakcja zarządzająca zewnętrznym dostępem do usług w klastrze,
    \item \textbf{configMap} i \textbf{Secret} - mechanizmy do przechowywania konfiguracji i tajnych danych,
    \item \textbf{namespace} - mechanizm do izolacji zasobów w klastrze.
\end{itemize}

\subsubsection{Zalety Kubernetes w kontekście analizy danych strumieniowych}
\label{subsubsec:zalety_kubernetes}

Platforma Kubernetes cechuje szereg zalet w kontekście rozproszonych systemów \cite{kubernetes_benefits}:

\begin{itemize}
    \item \textbf{automatyczne skalowanie} - możliwość automatycznego dostosowywania liczby replik usług w zależności od obciążenia,
    \item \textbf{samonaprawianie} - automatyczne ponowne uruchamianie podów doznających awarii,
    \item \textbf{równoważenie obciążenia} - równomierne rozłożenie ruchu między replikami usług,
    \item \textbf{aktualizacje bez przestojów} - możliwość aktualizacji usług bez przerywania ich działania,
    \item \textbf{deklaratywna konfiguracja} - definiowanie pożądanego stanu systemu, a nie kroków do jego osiągnięcia.
\end{itemize}

\subsection{Narzędzia \mbox{Big Data} do przetwarzania strumieniowego}
\label{subsec:narzedzia_big_data}

W kontekście analizy danych strumieniowych szczególnie istotne są narzędzia \mbox{Big Data} do przetwarzania strumieniowego \cite{spark_streaming}.
Poniżej omówiono kilka kluczowych technologii wykorzystywanych w tym obszarze.

\subsubsection{Broker \mbox{Apache Kafka}}
\label{subsubsec:apache_kafka}

\mbox{Apache Kafka} \cite{kafka} to rozproszona platforma do przetwarzania strumieniowego, opracowana przez \textit{LinkedIn} (portal społecznościowy), obecnie rozwijana jako projekt
organizacji \\ \mbox{Apache Software Foundation} (fundacja rozwijająca oprogramowanie open source). 

\vspace{0.3em}

Broker Kafki oferuje następujące możliwości:

\begin{itemize}
    \item \textbf{wysoka przepustowość} - możliwość obsługi milionów wiadomości na sekundę,
    \item \textbf{trwałość danych} - informacje są przechowywane na dysku i replikowane między brokerami,
    \item \textbf{skalowalność} - łatwe skalowanie poziome przez dodawanie nowych brokerów,
    \item \textbf{mechanizm partycjonowania} - umożliwia równoległe przetwarzanie danych,
    \item \textbf{gwarancje dostarczania} - co najmniej raz, co najwyżej raz lub dokładnie raz.
\end{itemize}

\subsubsection{Biblioteka \mbox{Kafka Streams}}
\label{subsubsec:kafka_streams}

\mbox{Kafka Streams} to biblioteka przetwarzania strumieniowego, zintegrowana z brokerem \\ \mbox{Apache Kafka} \cite{kafka_streams}. 

\vspace{0.3em}

Oferuje następujące możliwości:

\begin{itemize}
    \item \textbf{przetwarzanie rekord po rekordzie} - minimalne opóźnienia przetwarzania,
    \item \textbf{operacje stanowe i bezstanowe} - możliwość agregacji danych w czasie,
    \item \textbf{okna czasowe} - przetwarzanie danych w zdefiniowanych oknach czasowych,
    \item \textbf{łączenie strumieni} - możliwość łączenia danych z różnych strumieni,
    \item \textbf{semantyka "dokładnie raz"} - gwarancje przetwarzania dokładnie raz, eliminujące duplikaty i utratę danych.
\end{itemize}

\subsubsection{Technologia \mbox{Apache Flink}}
\label{subsubsec:apache_flink}

\mbox{Apache Flink} to framework i rozproszony silnik przetwarzania do obliczeń stanowych na nieograniczonych i ograniczonych strumieniach danych, oferujący możliwości podobne do biblioteki \mbox{Kafka Streams},
ale jako oddzielna platforma \cite{flink}. 

\vspace{0.3em}

Platforma Flink charakteryzuje się:

\begin{itemize}
    \item \textbf{niskimi opóźnieniami} - przetwarzanie rekord po rekordzie z minimalnymi opóźnieniami,
    \item \textbf{wysoką przepustowością} - efektywne przetwarzanie dużych wolumenów danych,
    \item \textbf{semantyka "dokładnie raz"} - gwarancje przetwarzania dokładnie raz,
    \item \textbf{zaawansowanym zarządzaniem stanem} - efektywne przechowywanie i dostęp do stanu przetwarzania,
    \item \textbf{obsługą czasu zdarzeń} - możliwość przetwarzania danych na podstawie czasu, w którym zdarzenia zostały wygenerowane.
\end{itemize}

\subsubsection{Moduł \mbox{Apache Spark Streaming}}
\label{subsubsec:spark_streaming}

\mbox{Apache Spark Streaming} to moduł przetwarzania strumieniowego platformy \mbox{Apache Spark} \cite{spark_streaming}.
Opiera się na modelu mikrowsadowym, gdzie dane są przetwarzane w małych pakietach. 

\vspace{0.3em}

Moduł Spark Streaming oferuje:

\begin{itemize}
    \item \textbf{integrację z ekosystemem Spark} - możliwość wykorzystania bibliotek Spark do analizy danych i uczenia maszynowego - ekosystem ten obejmuje m.in. \mbox{Spark SQL} do przetwarzania danych strukturalnych \cite{chambers2018spark} oraz \mbox{Spark ML} (\mbox{Machine Learning Library}) do implementacji algorytmów uczenia maszynowego \cite{chambers2018spark},
    \item \textbf{wysoką przepustowość} - efektywne przetwarzanie dużych wolumenów danych,
    \item \textbf{odporność na awarie} - automatyczne odtwarzanie stanu po awarii,
    \item \textbf{łatwe skalowanie} - możliwość łatwego skalowania przetwarzania przez dodawanie węzłów.
\end{itemize}

\subsubsection{Platformy \mbox{Apache Avro} i \mbox{Confluent Schema Registry}}
\label{subsubsec:avro_schema_registry}

W rozproszonych systemach przetwarzania danych, zwłaszcza tych wykorzystujących platformę \mbox{Apache Kafka}, kluczowe znaczenie ma efektywna ich serializacja oraz zarządzanie ich schematami. Pozwala to na minimalizację narzutu komunikacyjnego oraz zapewnienie spójności i kompatybilności danych między różnymi komponentami systemu.

\textit{\mbox{Apache Avro}} to format serializacji danych oparty na schematach, zapewniający kompaktową reprezentację binarną oraz bogate możliwości ewolucji schematów \cite{avro_documentation}. Dzięki temu możliwe jest modyfikowanie struktury danych bez zakłócania pracy istniejących producentów i konsumentów. Format \mbox{Apache Avro} jest szczególnie popularne w ekosystemie \mbox{Apache Kafka} ze względu na swoją wydajność i elastyczność.

\textit{\mbox{Confluent Schema Registry}} to usługa działająca jako centralne repozytorium schematów (m.in. Avro, \mbox{JSON Schema} (standard schematów JSON) \cite{json_schema_spec}, \mbox{Protobuf} (format serializacji protokołów) \cite{protobuf_docs}) \cite{confluent_schema_registry}. Integruje się z klientami Kafka, umożliwiając automatyczną rejestrację, walidację i pobieranie schematów podczas serializacji i deserializacji wiadomości. 

Usługa \mbox{Confluent Schema Registry} pomaga w utrzymaniu jakości danych, zapobiega problemom związanym z niekompatybilnością schematów oraz ułatwia zarządzanie zmianami w strukturze danych w dynamicznie rozwijających się systemach. W ramach opisywanego projektu, usługa \mbox{Confluent Schema Registry} zostało wykorzystane do zarządzania schematami Avro dla danych przesyłanych przez broker \mbox{Apache Kafka}.

\subsection{Istniejące narzędzia analizy danych i ich ograniczenia}
\label{subsec:istniejace_rozwiazania}

W literaturze i praktyce przemysłowej istnieje szereg rozwiązań do analizy danych z systemów wieloczujnikowych. Poniżej omówiono kilka z nich, wraz z ich ograniczeniami.

\subsubsection{Tradycyjne systemy SCADA}
\label{subsubsec:scada}

Systemy SCADA (systemy nadzoru i zbierania danych) to tradycyjne rozwiązania do monitorowania i kontroli procesów przemysłowych \cite{scada}.
Mimo popularności, systemy te mają pewne ograniczenia w kontekście analizy danych w czasie rzeczywistym:

\begin{itemize}
    \item \textbf{ograniczona skalowalność} - trudności w obsłudze dużej liczby czujników i strumieni danych,
    \item \textbf{monolityczna architektura} - utrudnia elastyczne rozwijanie i modyfikowanie systemu,
    \item \textbf{ograniczone możliwości analityczne} - często koncentrują się na wizualizacji danych, a nie ich głębokiej analizie,
    \item \textbf{wysokie koszty licencji} - komercyjne systemy SCADA często wiążą się z wysokimi kosztami licencji.
\end{itemize}

\subsubsection{Platformy IoT w chmurze}
\label{subsubsec:cloud_iot}

Platformy IoT (Internet Rzeczy) w chmurze, takie jak: AWS IoT (usługa firmy Amazon), Azure IoT Hub (usługa firmy Microsoft) czy Google Cloud IoT Core (usługa firmy Google), oferują zaawansowane możliwości analizy danych z
urządzeń IoT \cite{cloud_iot}. Mimo to, mają pewne ograniczenia:

\begin{itemize}
    \item \textbf{zależność od dostawcy chmury} - trudności w migracji między różnymi dostawcami,
    \item \textbf{koszty transferu danych} - wysokie koszty przy dużym wolumenie danych,
    \item \textbf{opóźnienia sieciowe} - potencjalne opóźnienia związane z przesyłaniem danych do chmury,
    \item \textbf{ograniczone możliwości dostosowania} - platformy chmurowe oferują określony zestaw usług, które mogą nie spełniać wszystkich wymagań.
\end{itemize}

\newpage

\subsubsection{Rozwiązania open source do analizy danych strumieniowych}
\label{subsubsec:open_source}

Istnieje szereg rozwiązań otwarto-źródłowych (oprogramowanie o otwartym kodzie źródłowym) do analizy danych w czasie rzeczywistym, takich jak: rozwiązanie \mbox{Apache NiFi} (narzędzie do przetwarzania danych) \cite{apache_nifi},
rozwiązanie \mbox{Apache Druid} (baza danych do analizy danych) \cite{apache_druid} czy baza danych \mbox{InfluxDB} (specjalistyczna baza danych szeregów czasowych) \cite{influxdb}. Mimo ich zalet, mają również pewne ograniczenia:

\begin{itemize}
    \item \textbf{złożoność wdrożenia} - konfiguracja i wdrożenie mogą być skomplikowane,
    \item \textbf{ograniczone wsparcie} - wsparcie techniczne może być ograniczone w porównaniu do rozwiązań komercyjnych,
    \item \textbf{konieczność integracji wielu narzędzi} - często wymagają integracji wielu narzędzi, co zwiększa złożoność systemu.
\end{itemize}

\vspace{0.3em}

Podsumowując, istniejące rozwiązania do analizy danych z systemów wieloczujnikowych mają pewne ograniczenia uzasadniające potrzebę opracowania nowego, autorskiego systemu, opartego na architekturze mikroserwisowej, klastrze Kubernetes i narzędziach \mbox{Big Data}.